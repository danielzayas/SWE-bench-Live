{
  "all_hints_text": "Thanks for creating the issue @degustaf \r\n\r\nYes, this is still a design goal that we'd want to achieve with `astroid`. There are two reasons for why this didn't happen yet, the first one being the one that you identified about not having enough time to do it. The second one is that it's a rather tricky issue, since there are various cyclic dependencies between `inference.py`, `protocols.py` and the rest of `astroid` files. We attempted to do this in the so called \"2.0\" branch of astroid (https://github.com/PyCQA/astroid/tree/2.0) which was an effort to reengineer most of astroid's architecture. If you look in that branch, you can see that we managed to reduce that monkeypatching quite a bit, if not all, but at this point, that branch is quite behind everything else and has a lot more changes that can't come easily in `master` without additional work.\r\n\r\nIf you're interested in helping, cherry-picking the refactoring for dropping the monkeypatch would be definitely amazing.\nCan someone provide some details on this please? \r\nastroid 2.0 branch is the default for a long time now, but Manticore's comment is quite recent.\r\nAre there any examples before-after? \r\n\r\nBut overall I just saw \"contributor friendly\" tag and wanted to see if I could be of any help.\nHey @gyermolenko ! This might not be contributor friendly after all, as it requires going through https://github.com/PyCQA/astroid/tree/2.0 and bringing back into `master` the removal of monkeypatching methods. The gist of the solution is the use of single dispatch to register inference functions: https://github.com/PyCQA/astroid/blob/2.0/astroid/inference.py#L37\n@DanielNoord made a start toward this by suggesting a new design where _nodes don't need to know how to infer themselves_ in #2167 (with a new `infer_object()` API).\r\n\r\nThen I suggested an alternative in #2171 where we keep the existing API and just define the methods on the classes where we expect them, and solve cyclic imports along the way.\r\n\r\nWe have consensus that we'd like to fix this in an alpha of astroid 3.0, but we don't have consensus yet on which direction to take. I'd like to flow out all the concerns folks raised to make sure everything is sounded out before choosing a direction.\r\n\r\n***\r\n#### Concerns with the infer_object()/`AstroidManager` approach:\r\n\r\n- [Requires \"looking up\" the inference method](https://github.com/pylint-dev/astroid/pull/2167#issuecomment-1546905250) through a series of isinstance() checks or a mapping from node types to inference methods\r\n  - JW: a mapping from node types to inference methods won't support subclassing (a la pylint's unidiomatic-type-check msg)\r\n  - JW: a series of isinstance() checks could commit us to a performance degradation\r\n  - DN: This could probably be improved upon with some better code-paths and more sharing of code-paths between node types, but it is indeed a cost.\r\n- [The nodes no longer know how to infer themselves](https://github.com/pylint-dev/astroid/pull/2167#discussion_r1186850743)\r\n  - JW: from the perspective of making astroid easier to work with, the indirection created here is, for me, slightly better than the status quo, because you no longer have to search through various long files to find the assignment of a method, but it still doesn't seem like a Pythonic design: the node inference methods are node-specific (rely on attributes of those specific nodes). It strikes me as unwanted indirection to have to use a map from a node to node-specific method instead of having that node-specific method defined on the node.\r\n  - DN: Is knowing how to infer themselves really the responsibility of the nodes? Personally I believe that having the nodes act as an (almost) drop-in replacement of `ast` and letting another part of the code handle the inferences of said nodes makes more sense. It means that the `nodes` module would just become a data layer over `ast` while all of the core logic can be moved into a separate module. That _should_ reduce/remove a lot of the interdependencies between the data/model layer and the layer that actually uses it.\r\n- API-breakage\r\n  - JW: I'm not sure what the final intended pattern is, e.g. if we're going to leave \"infer()\" as a shim forever--and accept a cyclic import of inference.infer_object--or if we're going to remove it. We have permission to remove interfaces in a major version, but the cost to users should be weighed in the total analysis as a minor factor.\r\n  - DN: I don't think in recent months/years we have seen many contributions from other users than `pylint`. In fact, the only person that was actively contributing for a longer period of time moved away because `astroid` is so incompatible. See https://github.com/pylint-dev/astroid/issues/1338 and other issues opened by them at that time. We don't seem to gain much from keeping API stability.\r\n\r\nDN: I'd also like to reiterate that I do think that `infer_object` is less than optimal and think that we can improve upon it considerably. However, I wanted to do this in smaller steps, see my subsequent PR as well. My main intent is to have on `AstroidManager` class (or something similar) that is the entry point for inference and doesn't have any global state. I believe this is the only way to make `pylint` at least somewhat useful in a `multiprocessing` environment.\r\n\r\n***\r\n#### Concerns with keeping the existing API and refactoring to avoid cyclic imports\r\n- [Introduces some mixin classes](https://github.com/pylint-dev/astroid/pull/2171#pullrequestreview-1425514532)\r\n    - JW: Personally, I rarely guard mixins against unintended instantiation. If there is concern about unintended instantiation, I'll just [get rid of the mixins and add a helper function](https://github.com/pylint-dev/astroid/pull/2171#discussion_r1193210178).\r\n    -  DN: I really dislikes Mixins as the Python tooling such as `mypy` and `pylint` doesn't handle them very well.\r\n - [Prevents decoupling nodes from inference in order to have a drop-in replacement for ast nodes](https://github.com/pylint-dev/astroid/pull/2167#issuecomment-1537439387)\r\n    - DN: See above as well. I think making `astroid` be more of a drop-in could (finally) increase the number of contributions.\r\n      - JW: Marc indicated [here](https://github.com/pylint-dev/astroid/issues/1361#issuecomment-1025275715) his inclination against viewing astroid as a drop-in replacement for ast nodes\r\n - [NodeNG.infer() depends on global AstroidManager state](https://github.com/pylint-dev/astroid/pull/2167#issuecomment-1546910655)\r\n   - DN: https://github.com/pylint-dev/astroid/blob/ee121600c07ecdab55d5fc9179b9bdf2cba0fd74/astroid/nodes/node_ng.py#L178. Although we could probably work around this there are multiple places in our code where we just do `AstroidManager()` and then use the global state. As said above, I don't see `infer_object` as the final version of the inference system but I do see it as a clearer step towards having an inference system that can be instantiated on demand and without any shared state.\r\n     - JW: I didn't follow this one, hoping to grok it after DN's updates. I understand that global state jeopardizes parallelism, but that seems like an orthogonal problem to me. Do you have an example of how #2167 would help in this regard?\r\n - [Composition when involving setting instance attributes](https://github.com/pylint-dev/astroid/pull/2167#issuecomment-1546910655)\r\n      - JW: Do you have an example of how #2167 would help in this regard? I didn't grok this.\r\n      -  DN: See above. I don't like how we use `postinit` and have to see instance attributes as class-scope typed attributes to make things work for `mypy`. Mixins make this even worse. To me those types seem like an anti-pattern that we should try and avoid. #2167 doesn't fix this, but also doesn't make the problem worse.\r\n- [The nodes modules will become longer](https://github.com/pylint-dev/astroid/pull/2171#pullrequestreview-1416999939)\r\n\r\nDN: What I don't really like about keeping the existing API is that I don't see a clear path towards some of the existing issues we have. Although you showed that it does allow us to fix some of the cyclic imports etc. for me it just doesn't click how making one class/type responsible for everything improves the state of the codebase. I think separation of concerns would be better and makes it easier to tackle individual problems. Perhaps I'm too influenced by my day to day work but I tend to see `astroid` as having a data and an application layer (with `pylint` being the frontend if you want to complete this comparison). Separation between the data modelling layer and the layer that interacts with it feels more natural to me, but that might just be my own preference.\nI hope to find time tonight to get back to this! My comment in https://github.com/pylint-dev/astroid/pull/2210 is also somewhat related to my general ideas about `astroid` startup.\nI have added my comments to the list. Let's continue the discussion in comments from now on and not keep editing the original post by Jacob.\nThanks, I really appreciate your taking the time to add notes!  I'm hoping the silly bullet-point debate-flow-outline might help others follow the discussions we had across several PRs. \ud83d\ude04\r\n\r\nI'll let this be my last post on the subject for a while, because if I drone on it could discourage other people from speaking up. \ud83d\udce3 \r\n\r\n***\r\nI'm hearing the arguments for the `infer_object()` approach[*] as mostly design-philosophical and priced with a \"we think this will make future fixes easier\" discount. That's not enough for a merge for me. I don't think making an inference a pure function instead of an instance method makes astroid either easier or harder to contribute to, or multiprocessing bugs either easier or harder to solve. Pure functions are beautiful! I spent a lot of the last year in React, which loves them. But even React has pragmatic escape-hatches when you need global state or side effects, and when we address the multiprocessing optimizations, we will ideally have less global state than now, but likely will still need a little global state, and then we'll need to put it somewhere, and then the pure `infer_object()` won't be so pure anymore. And then I'll be back where I started, wondering why we merged it (and potentially with new things to optimize, like the isisnstance checks).\r\n\r\nOr not! But it's too early to know. Is this PR supposed to be the first PR in a series of PRs to fix multiprocessing? It seems to me like the wrong place to start. Or, in other words, it seems like only one person has a mental roadmap of how `infer_object()` would pay off for multiprocessing. Pierre [indicated](https://github.com/pylint-dev/astroid/pull/2167#issuecomment-1579358424) a similar hesitation. (I did look at the second PR, which I took to be #2168, but it just removes the monkey-patching, which we've already agreed both PRs do just fine.)\r\n\r\n[*] just noticed that @DanielNoord edited the post to clarify that it's the \"`infer_object()`/`AstroidManager`\" approach, but this is the crux of the whole thing: I don't see the two as connected. I'll gladly work on PRs on the AstroidManager after merging my alternative to just get rid of the monkey patching. I feel like the in-person analogue of where we're at right now is that we have two contributors looking at a whiteboard and making opposite educated guesses; in that scenario, I think it's better to merge the consensual parts: just removing the monkey-patching.\r\n\r\n***\r\n> My main intent is to have on AstroidManager class (or something similar) that is the entry point for inference and doesn't have any global state. I believe this is the only way to make pylint at least somewhat useful in a multiprocessing environment.\r\n\r\nSame as above, I'm not convinced this would be the only way to do that? I'd rather see at least some proof-of-concept of some element of removing global state and how infer_object() is necessary to make it work.\r\n\r\n\r\n> What I don't really like about keeping the existing API is that I don't see a clear path towards some of the existing issues we have. Although you showed that it does allow us to fix some of the cyclic imports etc. for me it just doesn't click how making one class/type responsible for everything improves the state of the codebase. I think separation of concerns would be better and makes it easier to tackle individual problems.\r\n\r\n\r\n> As said above, I don't see infer_object as the final version of the inference system but I do see it as a clearer step towards having an inference system that can be instantiated on demand and without any shared state.\r\n\r\nTo avoid repeating myself :D...\r\nThe multiprocessing bugs: just a cyclic-import behavior bug and then optimizing to make sure we actually are parallelizing the right things, right? Performance optimizations can be very surprising; it's better to optimize from reasoning about the existing system and profiling it, not from heuristics and design philosophy. This is why I'm so hesitant.\r\n\r\n> I think making astroid be more of a drop-in could (finally) increase the number of contributions.\r\n\r\nI confess to not even being sure how this would work. A few lines of pseudocode would help, if you're up for it. What do people want with the astroid library if they don't want inference? I know there was a comment along these lines from PCManticore in https://github.com/pylint-dev/astroid/issues/169#issuecomment-163118560, though.\r\n\r\nI think the most impactful intervention for new contributors would be continuing to use the good-first-issues label and ensuring we don't ask for big refactors along the way. (The str/repr PR in #2198 was a good experience, I felt!)\n> I'm hearing the arguments for the `infer_object()` approach[*] as mostly design-philosophical and priced with a \"we think this will make future fixes easier\" discount. That's not enough for a merge for me. \r\n\r\nThis is fair. I think the counter-argument is why I am so hesitant for the other approach: I don't see the end-goal and only a fix for one particular issue. We have so many difficulties with getting `astroid` fully typed an into a more modern codebase that support parallelisation that I think we would benefit from a more clear migration path (similar to the famous V2 branch). Since the end-goal I envisioned is 180 degrees different to what you propose in that PR I find it hard to see how we go to a truly better design from there.\r\n\r\n> Is this PR supposed to be the first PR in a series of PRs to fix multiprocessing? It seems to me like the wrong place to start.\r\n\r\nThis is basically my argument above reworded in my opinion \ud83d\ude04 What is the end objective of that PR? And if there isn't one: shouldn't there be one?\r\n\r\n> Or, in other words, it seems like only one person has a mental roadmap of how `infer_object()` would pay off for multiprocessing. \r\n\r\nI agree, I should have discussed this more clearly.\r\n\r\n> I feel like the in-person analogue of where we're at right now is that we have two contributors looking at a whiteboard and making opposite educated guesses; in that scenario, I think it's better to merge the consensual parts: just removing the monkey-patching.\r\n\r\n\ud83d\udc4d\r\n\r\n> Same as above, I'm not convinced this would be the only way to do that? I'd rather see at least some proof-of-concept of some element of removing global state and how infer_object() is necessary to make it work.\r\n\r\nI think this is more of a philosophical/design decision. Like I said, to me it feels like we should disconnect the data and the data-handling as they have different responsibilities. `infer_object` is a move towards such a distinction, that's why it is connected in my mind.\r\n\r\n> To avoid repeating myself :D... The multiprocessing bugs: just a cyclic-import behavior bug and then optimizing to make sure we actually are parallelizing the right things, right?\r\n\r\nSee https://github.com/pylint-dev/astroid/issues/2048. In the current setup I don't think we can parallelise what we should. That's an issue \ud83d\ude04 \r\n\r\n> I confess to not even being sure how this would work. A few lines of pseudocode would help, if you're up for it. What do people want with the astroid library if they don't want inference? I know there was a comment along these lines from PCManticore in [#169 (comment)](https://github.com/pylint-dev/astroid/issues/169#issuecomment-163118560), though.\r\n\r\nWell, in https://github.com/pylint-dev/astroid/issues/1338 I know the author was trying to replace `ast` with `astroid` in a tool they wrote but weren't able to due to the API incompatibilities. I think they will likely want to have inference but if they could just do `AstroidManager().infer_this_node_for_me(node)` that would probably also be fine for them. By keeping the API of the nodes simple, minimal and mostly in line with `ast` they would have been able to use `astroid` as a replacement.\r\n\r\n> I think the most impactful intervention for new contributors would be continuing to use the good-first-issues label and ensuring we don't ask for big refactors along the way. (The str/repr PR in #2198 was a good experience, I felt!)\r\n\r\nAgreed!\r\n\n\n",
  "base_commit": "8d57ce2f3e226c2ac3cdd7f6a57dac2dd5ec5a4b",
  "commit_urls": [
    "https://github.com/pylint-dev/astroid/commit/ed843e9a5d4dfb4f5cd7885055c8b388d325a22c",
    "https://github.com/pylint-dev/astroid/commit/60f02def33c977b2712f946412027b992cf8f801",
    "https://github.com/pylint-dev/astroid/commit/e910116a7c2d2ce714d03748348ab07409d49f1e",
    "https://github.com/pylint-dev/astroid/commit/1688426a76c8f767aafb8dff919ab38f4c76f746",
    "https://github.com/pylint-dev/astroid/commit/fd17782d913df7cb706eb529a9460c2d1645e38b",
    "https://github.com/pylint-dev/astroid/commit/3bc4588d3ca6d940886604aa158d037476e26d20",
    "https://github.com/pylint-dev/astroid/commit/27d150b5fa897e8d356a47c957a0adaf815af342",
    "https://github.com/pylint-dev/astroid/commit/c8f0d2eb1adfb863b9a7b9f2a14477153e813202",
    "https://github.com/pylint-dev/astroid/commit/ceff22c1c156d2a4f94ccaaa8efe5d75d93ddb03",
    "https://github.com/pylint-dev/astroid/commit/76c10af85bb21318e251ae5b54a254c2dfdbad79",
    "https://github.com/pylint-dev/astroid/commit/80c0391e775554e5a1fee8cc93b00c753f6b68e5"
  ],
  "created_at": "2023-05-08T15:00:30Z",
  "hints_text": "Thanks for creating the issue @degustaf \r\n\r\nYes, this is still a design goal that we'd want to achieve with `astroid`. There are two reasons for why this didn't happen yet, the first one being the one that you identified about not having enough time to do it. The second one is that it's a rather tricky issue, since there are various cyclic dependencies between `inference.py`, `protocols.py` and the rest of `astroid` files. We attempted to do this in the so called \"2.0\" branch of astroid (https://github.com/PyCQA/astroid/tree/2.0) which was an effort to reengineer most of astroid's architecture. If you look in that branch, you can see that we managed to reduce that monkeypatching quite a bit, if not all, but at this point, that branch is quite behind everything else and has a lot more changes that can't come easily in `master` without additional work.\r\n\r\nIf you're interested in helping, cherry-picking the refactoring for dropping the monkeypatch would be definitely amazing.\nCan someone provide some details on this please? \r\nastroid 2.0 branch is the default for a long time now, but Manticore's comment is quite recent.\r\nAre there any examples before-after? \r\n\r\nBut overall I just saw \"contributor friendly\" tag and wanted to see if I could be of any help.\nHey @gyermolenko ! This might not be contributor friendly after all, as it requires going through https://github.com/PyCQA/astroid/tree/2.0 and bringing back into `master` the removal of monkeypatching methods. The gist of the solution is the use of single dispatch to register inference functions: https://github.com/PyCQA/astroid/blob/2.0/astroid/inference.py#L37\n\n",
  "instance_id": "pylint-dev__astroid-2171",
  "issue_numbers": [
    679
  ],
  "language": "python",
  "patch": "diff --git a/ChangeLog b/ChangeLog\nindex d05a19c909..0a4414809d 100644\n--- a/ChangeLog\n+++ b/ChangeLog\n@@ -19,6 +19,13 @@ Release date: TBA\n   Closes #1780\n   Refs #2140\n \n+* Remove the ``inference`` module. Node inference methods are now in the module\n+  defining the node, rather than being associated to the node afterward.\n+\n+  Closes #679\n+\n+* Move ``LookupMixIn`` to ``astroid.nodes._base_nodes`` and make it private.\n+\n * Reduce file system access in ``ast_from_file()``.\n \n * Reduce time to ``import astroid`` by delaying ``astroid_bootstrapping()`` until\ndiff --git a/astroid/__init__.py b/astroid/__init__.py\nindex f3c2c79018..29e052e1f7 100644\n--- a/astroid/__init__.py\n+++ b/astroid/__init__.py\n@@ -40,7 +40,7 @@\n \n # isort: on\n \n-from astroid import inference, raw_building\n+from astroid import raw_building\n from astroid.__pkginfo__ import __version__, version\n from astroid.astroid_manager import MANAGER\n from astroid.bases import BaseInstance, BoundMethod, Instance, UnboundMethod\ndiff --git a/astroid/bases.py b/astroid/bases.py\nindex 2f756a615e..bd8f6bb958 100644\n--- a/astroid/bases.py\n+++ b/astroid/bases.py\n@@ -10,9 +10,9 @@\n import collections\n import collections.abc\n from collections.abc import Iterable, Iterator\n-from typing import TYPE_CHECKING, Any, ClassVar, Literal\n+from typing import TYPE_CHECKING, Any, Literal\n \n-from astroid import nodes\n+from astroid import decorators, nodes\n from astroid.const import PY310_PLUS\n from astroid.context import (\n     CallContext,\n@@ -28,7 +28,6 @@\n )\n from astroid.interpreter import objectmodel\n from astroid.typing import (\n-    InferBinaryOp,\n     InferenceErrorInfo,\n     InferenceResult,\n     SuccessfulInferenceResult,\n@@ -346,7 +345,16 @@ class Instance(BaseInstance):\n     def __init__(self, proxied: nodes.ClassDef | None) -> None:\n         super().__init__(proxied)\n \n-    infer_binary_op: ClassVar[InferBinaryOp[Instance]]\n+    @decorators.yes_if_nothing_inferred\n+    def infer_binary_op(\n+        self,\n+        opnode: nodes.AugAssign | nodes.BinOp,\n+        operator: str,\n+        other: InferenceResult,\n+        context: InferenceContext,\n+        method: SuccessfulInferenceResult,\n+    ) -> Generator[InferenceResult, None, None]:\n+        return method.infer_call_result(self, context)\n \n     def __repr__(self) -> str:\n         return \"<Instance of {}.{} at 0x{}>\".format(\ndiff --git a/astroid/constraint.py b/astroid/constraint.py\nindex 6e23b592f1..08bb80e3c9 100644\n--- a/astroid/constraint.py\n+++ b/astroid/constraint.py\n@@ -8,9 +8,9 @@\n import sys\n from abc import ABC, abstractmethod\n from collections.abc import Iterator\n-from typing import Union\n+from typing import TYPE_CHECKING, Union\n \n-from astroid import bases, nodes, util\n+from astroid import nodes, util\n from astroid.typing import InferenceResult\n \n if sys.version_info >= (3, 11):\n@@ -18,6 +18,9 @@\n else:\n     from typing_extensions import Self\n \n+if TYPE_CHECKING:\n+    from astroid import bases\n+\n _NameNodes = Union[nodes.AssignAttr, nodes.Attribute, nodes.AssignName, nodes.Name]\n \n \ndiff --git a/astroid/filter_statements.py b/astroid/filter_statements.py\nindex 7f040dd4ed..acca676170 100644\n--- a/astroid/filter_statements.py\n+++ b/astroid/filter_statements.py\n@@ -10,10 +10,14 @@\n \n from __future__ import annotations\n \n+from typing import TYPE_CHECKING\n+\n from astroid import nodes\n-from astroid.nodes import node_classes\n from astroid.typing import SuccessfulInferenceResult\n \n+if TYPE_CHECKING:\n+    from astroid.nodes import _base_nodes\n+\n \n def _get_filtered_node_statements(\n     base_node: nodes.NodeNG, stmt_nodes: list[nodes.NodeNG]\n@@ -44,7 +48,7 @@ def _get_if_statement_ancestor(node: nodes.NodeNG) -> nodes.If | None:\n \n \n def _filter_stmts(\n-    base_node: node_classes.LookupMixIn,\n+    base_node: _base_nodes.LookupMixIn,\n     stmts: list[SuccessfulInferenceResult],\n     frame: nodes.LocalsDictNodeNG,\n     offset: int,\ndiff --git a/astroid/helpers.py b/astroid/helpers.py\nindex ab5ada3715..3e62fb99eb 100644\n--- a/astroid/helpers.py\n+++ b/astroid/helpers.py\n@@ -324,3 +324,25 @@ def object_len(node, context: InferenceContext | None = None):\n     raise AstroidTypeError(\n         f\"'{result_of_len}' object cannot be interpreted as an integer\"\n     )\n+\n+\n+def _higher_function_scope(node: nodes.NodeNG) -> nodes.FunctionDef | None:\n+    \"\"\"Search for the first function which encloses the given\n+    scope.\n+\n+    This can be used for looking up in that function's\n+    scope, in case looking up in a lower scope for a particular\n+    name fails.\n+\n+    :param node: A scope node.\n+    :returns:\n+        ``None``, if no parent function scope was found,\n+        otherwise an instance of :class:`astroid.nodes.scoped_nodes.Function`,\n+        which encloses the given node.\n+    \"\"\"\n+    current = node\n+    while current.parent and not isinstance(current.parent, nodes.FunctionDef):\n+        current = current.parent\n+    if current and current.parent:\n+        return current.parent\n+    return None\ndiff --git a/astroid/inference.py b/astroid/inference.py\ndeleted file mode 100644\nindex d7caddc575..0000000000\n--- a/astroid/inference.py\n+++ /dev/null\n@@ -1,1293 +0,0 @@\n-# Licensed under the LGPL: https://www.gnu.org/licenses/old-licenses/lgpl-2.1.en.html\n-# For details: https://github.com/pylint-dev/astroid/blob/main/LICENSE\n-# Copyright (c) https://github.com/pylint-dev/astroid/blob/main/CONTRIBUTORS.txt\n-\n-\"\"\"This module contains a set of functions to handle inference on astroid trees.\"\"\"\n-\n-from __future__ import annotations\n-\n-import ast\n-import functools\n-import itertools\n-import operator\n-import typing\n-from collections.abc import Callable, Generator, Iterable, Iterator\n-from typing import TYPE_CHECKING, Any, Optional, TypeVar, Union\n-\n-from astroid import (\n-    bases,\n-    constraint,\n-    decorators,\n-    helpers,\n-    nodes,\n-    objects,\n-    protocols,\n-    util,\n-)\n-from astroid.const import PY310_PLUS\n-from astroid.context import (\n-    CallContext,\n-    InferenceContext,\n-    bind_context_to_node,\n-    copy_context,\n-)\n-from astroid.exceptions import (\n-    AstroidBuildingError,\n-    AstroidError,\n-    AstroidIndexError,\n-    AstroidTypeError,\n-    AstroidValueError,\n-    AttributeInferenceError,\n-    InferenceError,\n-    NameInferenceError,\n-    _NonDeducibleTypeHierarchy,\n-)\n-from astroid.interpreter import dunder_lookup\n-from astroid.manager import AstroidManager\n-from astroid.typing import (\n-    InferenceErrorInfo,\n-    InferenceResult,\n-    SuccessfulInferenceResult,\n-)\n-\n-if TYPE_CHECKING:\n-    from astroid.objects import Property\n-\n-\n-_T = TypeVar(\"_T\")\n-_BaseContainerT = TypeVar(\"_BaseContainerT\", bound=nodes.BaseContainer)\n-_FunctionDefT = TypeVar(\"_FunctionDefT\", bound=nodes.FunctionDef)\n-\n-GetFlowFactory = typing.Callable[\n-    [\n-        InferenceResult,\n-        Optional[InferenceResult],\n-        Union[nodes.AugAssign, nodes.BinOp],\n-        InferenceResult,\n-        Optional[InferenceResult],\n-        InferenceContext,\n-        InferenceContext,\n-    ],\n-    \"list[functools.partial[Generator[InferenceResult, None, None]]]\",\n-]\n-\n-# .infer method ###############################################################\n-\n-\n-def infer_end(\n-    self: _T, context: InferenceContext | None = None, **kwargs: Any\n-) -> Iterator[_T]:\n-    \"\"\"Inference's end for nodes that yield themselves on inference.\n-\n-    These are objects for which inference does not have any semantic,\n-    such as Module or Consts.\n-    \"\"\"\n-    yield self\n-\n-\n-# We add ignores to all assignments to methods\n-# See https://github.com/python/mypy/issues/2427\n-nodes.Module._infer = infer_end\n-nodes.ClassDef._infer = infer_end\n-nodes.Lambda._infer = infer_end  # type: ignore[assignment]\n-nodes.Const._infer = infer_end  # type: ignore[assignment]\n-nodes.Slice._infer = infer_end  # type: ignore[assignment]\n-nodes.TypeAlias._infer = infer_end  # type: ignore[assignment]\n-nodes.TypeVar._infer = infer_end  # type: ignore[assignment]\n-nodes.ParamSpec._infer = infer_end  # type: ignore[assignment]\n-nodes.TypeVarTuple._infer = infer_end  # type: ignore[assignment]\n-\n-\n-def _infer_sequence_helper(\n-    node: _BaseContainerT, context: InferenceContext | None = None\n-) -> list[SuccessfulInferenceResult]:\n-    \"\"\"Infer all values based on _BaseContainer.elts.\"\"\"\n-    values = []\n-\n-    for elt in node.elts:\n-        if isinstance(elt, nodes.Starred):\n-            starred = helpers.safe_infer(elt.value, context)\n-            if not starred:\n-                raise InferenceError(node=node, context=context)\n-            if not hasattr(starred, \"elts\"):\n-                raise InferenceError(node=node, context=context)\n-            values.extend(_infer_sequence_helper(starred))\n-        elif isinstance(elt, nodes.NamedExpr):\n-            value = helpers.safe_infer(elt.value, context)\n-            if not value:\n-                raise InferenceError(node=node, context=context)\n-            values.append(value)\n-        else:\n-            values.append(elt)\n-    return values\n-\n-\n-@decorators.raise_if_nothing_inferred\n-def infer_sequence(\n-    self: _BaseContainerT,\n-    context: InferenceContext | None = None,\n-    **kwargs: Any,\n-) -> Iterator[_BaseContainerT]:\n-    has_starred_named_expr = any(\n-        isinstance(e, (nodes.Starred, nodes.NamedExpr)) for e in self.elts\n-    )\n-    if has_starred_named_expr:\n-        values = _infer_sequence_helper(self, context)\n-        new_seq = type(self)(\n-            lineno=self.lineno,\n-            col_offset=self.col_offset,\n-            parent=self.parent,\n-            end_lineno=self.end_lineno,\n-            end_col_offset=self.end_col_offset,\n-        )\n-        new_seq.postinit(values)\n-\n-        yield new_seq\n-    else:\n-        yield self\n-\n-\n-nodes.List._infer = infer_sequence  # type: ignore[assignment]\n-nodes.Tuple._infer = infer_sequence  # type: ignore[assignment]\n-nodes.Set._infer = infer_sequence  # type: ignore[assignment]\n-\n-\n-def infer_map(\n-    self: nodes.Dict, context: InferenceContext | None = None\n-) -> Iterator[nodes.Dict]:\n-    if not any(isinstance(k, nodes.DictUnpack) for k, _ in self.items):\n-        yield self\n-    else:\n-        items = _infer_map(self, context)\n-        new_seq = type(self)(\n-            self.lineno,\n-            self.col_offset,\n-            self.parent,\n-            end_lineno=self.end_lineno,\n-            end_col_offset=self.end_col_offset,\n-        )\n-        new_seq.postinit(list(items.items()))\n-        yield new_seq\n-\n-\n-def _update_with_replacement(\n-    lhs_dict: dict[SuccessfulInferenceResult, SuccessfulInferenceResult],\n-    rhs_dict: dict[SuccessfulInferenceResult, SuccessfulInferenceResult],\n-) -> dict[SuccessfulInferenceResult, SuccessfulInferenceResult]:\n-    \"\"\"Delete nodes that equate to duplicate keys.\n-\n-    Since an astroid node doesn't 'equal' another node with the same value,\n-    this function uses the as_string method to make sure duplicate keys\n-    don't get through\n-\n-    Note that both the key and the value are astroid nodes\n-\n-    Fixes issue with DictUnpack causing duplicate keys\n-    in inferred Dict items\n-\n-    :param lhs_dict: Dictionary to 'merge' nodes into\n-    :param rhs_dict: Dictionary with nodes to pull from\n-    :return : merged dictionary of nodes\n-    \"\"\"\n-    combined_dict = itertools.chain(lhs_dict.items(), rhs_dict.items())\n-    # Overwrite keys which have the same string values\n-    string_map = {key.as_string(): (key, value) for key, value in combined_dict}\n-    # Return to dictionary\n-    return dict(string_map.values())\n-\n-\n-def _infer_map(\n-    node: nodes.Dict, context: InferenceContext | None\n-) -> dict[SuccessfulInferenceResult, SuccessfulInferenceResult]:\n-    \"\"\"Infer all values based on Dict.items.\"\"\"\n-    values: dict[SuccessfulInferenceResult, SuccessfulInferenceResult] = {}\n-    for name, value in node.items:\n-        if isinstance(name, nodes.DictUnpack):\n-            double_starred = helpers.safe_infer(value, context)\n-            if not double_starred:\n-                raise InferenceError\n-            if not isinstance(double_starred, nodes.Dict):\n-                raise InferenceError(node=node, context=context)\n-            unpack_items = _infer_map(double_starred, context)\n-            values = _update_with_replacement(values, unpack_items)\n-        else:\n-            key = helpers.safe_infer(name, context=context)\n-            safe_value = helpers.safe_infer(value, context=context)\n-            if any(not elem for elem in (key, safe_value)):\n-                raise InferenceError(node=node, context=context)\n-            # safe_value is SuccessfulInferenceResult as bool(Uninferable) == False\n-            values = _update_with_replacement(values, {key: safe_value})\n-    return values\n-\n-\n-nodes.Dict._infer = infer_map  # type: ignore[assignment]\n-\n-\n-def _higher_function_scope(node: nodes.NodeNG) -> nodes.FunctionDef | None:\n-    \"\"\"Search for the first function which encloses the given\n-    scope. This can be used for looking up in that function's\n-    scope, in case looking up in a lower scope for a particular\n-    name fails.\n-\n-    :param node: A scope node.\n-    :returns:\n-        ``None``, if no parent function scope was found,\n-        otherwise an instance of :class:`astroid.nodes.scoped_nodes.Function`,\n-        which encloses the given node.\n-    \"\"\"\n-    current = node\n-    while current.parent and not isinstance(current.parent, nodes.FunctionDef):\n-        current = current.parent\n-    if current and current.parent:\n-        return current.parent  # type: ignore[no-any-return]\n-    return None\n-\n-\n-def infer_name(\n-    self: nodes.Name | nodes.AssignName,\n-    context: InferenceContext | None = None,\n-    **kwargs: Any,\n-) -> Generator[InferenceResult, None, None]:\n-    \"\"\"Infer a Name: use name lookup rules.\"\"\"\n-    frame, stmts = self.lookup(self.name)\n-    if not stmts:\n-        # Try to see if the name is enclosed in a nested function\n-        # and use the higher (first function) scope for searching.\n-        parent_function = _higher_function_scope(self.scope())\n-        if parent_function:\n-            _, stmts = parent_function.lookup(self.name)\n-\n-        if not stmts:\n-            raise NameInferenceError(\n-                name=self.name, scope=self.scope(), context=context\n-            )\n-    context = copy_context(context)\n-    context.lookupname = self.name\n-    context.constraints[self.name] = constraint.get_constraints(self, frame)\n-\n-    return bases._infer_stmts(stmts, context, frame)\n-\n-\n-# The order of the decorators here is important\n-# See https://github.com/pylint-dev/astroid/commit/0a8a75db30da060a24922e05048bc270230f5\n-nodes.Name._infer = decorators.raise_if_nothing_inferred(\n-    decorators.path_wrapper(infer_name)\n-)\n-nodes.AssignName.infer_lhs = infer_name  # won't work with a path wrapper\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_call(\n-    self: nodes.Call, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, InferenceErrorInfo]:\n-    \"\"\"Infer a Call node by trying to guess what the function returns.\"\"\"\n-    callcontext = copy_context(context)\n-    callcontext.boundnode = None\n-    if context is not None:\n-        callcontext.extra_context = _populate_context_lookup(self, context.clone())\n-\n-    for callee in self.func.infer(context):\n-        if isinstance(callee, util.UninferableBase):\n-            yield callee\n-            continue\n-        try:\n-            if hasattr(callee, \"infer_call_result\"):\n-                callcontext.callcontext = CallContext(\n-                    args=self.args, keywords=self.keywords, callee=callee\n-                )\n-                yield from callee.infer_call_result(caller=self, context=callcontext)\n-        except InferenceError:\n-            continue\n-    return InferenceErrorInfo(node=self, context=context)\n-\n-\n-nodes.Call._infer = infer_call  # type: ignore[assignment]\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_import(\n-    self: nodes.Import,\n-    context: InferenceContext | None = None,\n-    asname: bool = True,\n-    **kwargs: Any,\n-) -> Generator[nodes.Module, None, None]:\n-    \"\"\"Infer an Import node: return the imported module/object.\"\"\"\n-    context = context or InferenceContext()\n-    name = context.lookupname\n-    if name is None:\n-        raise InferenceError(node=self, context=context)\n-\n-    try:\n-        if asname:\n-            yield self.do_import_module(self.real_name(name))\n-        else:\n-            yield self.do_import_module(name)\n-    except AstroidBuildingError as exc:\n-        raise InferenceError(node=self, context=context) from exc\n-\n-\n-nodes.Import._infer = infer_import\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_import_from(\n-    self: nodes.ImportFrom,\n-    context: InferenceContext | None = None,\n-    asname: bool = True,\n-    **kwargs: Any,\n-) -> Generator[InferenceResult, None, None]:\n-    \"\"\"Infer a ImportFrom node: return the imported module/object.\"\"\"\n-    context = context or InferenceContext()\n-    name = context.lookupname\n-    if name is None:\n-        raise InferenceError(node=self, context=context)\n-    if asname:\n-        try:\n-            name = self.real_name(name)\n-        except AttributeInferenceError as exc:\n-            # See https://github.com/pylint-dev/pylint/issues/4692\n-            raise InferenceError(node=self, context=context) from exc\n-    try:\n-        module = self.do_import_module()\n-    except AstroidBuildingError as exc:\n-        raise InferenceError(node=self, context=context) from exc\n-\n-    try:\n-        context = copy_context(context)\n-        context.lookupname = name\n-        stmts = module.getattr(name, ignore_locals=module is self.root())\n-        return bases._infer_stmts(stmts, context)\n-    except AttributeInferenceError as error:\n-        raise InferenceError(\n-            str(error), target=self, attribute=name, context=context\n-        ) from error\n-\n-\n-nodes.ImportFrom._infer = infer_import_from  # type: ignore[assignment]\n-\n-\n-def infer_attribute(\n-    self: nodes.Attribute | nodes.AssignAttr,\n-    context: InferenceContext | None = None,\n-    **kwargs: Any,\n-) -> Generator[InferenceResult, None, InferenceErrorInfo]:\n-    \"\"\"Infer an Attribute node by using getattr on the associated object.\"\"\"\n-    for owner in self.expr.infer(context):\n-        if isinstance(owner, util.UninferableBase):\n-            yield owner\n-            continue\n-\n-        context = copy_context(context)\n-        old_boundnode = context.boundnode\n-        try:\n-            context.boundnode = owner\n-            if isinstance(owner, (nodes.ClassDef, bases.Instance)):\n-                frame = owner if isinstance(owner, nodes.ClassDef) else owner._proxied\n-                context.constraints[self.attrname] = constraint.get_constraints(\n-                    self, frame=frame\n-                )\n-            yield from owner.igetattr(self.attrname, context)\n-        except (\n-            AttributeInferenceError,\n-            InferenceError,\n-            AttributeError,\n-        ):\n-            pass\n-        finally:\n-            context.boundnode = old_boundnode\n-    return InferenceErrorInfo(node=self, context=context)\n-\n-\n-# The order of the decorators here is important\n-# See https://github.com/pylint-dev/astroid/commit/0a8a75db30da060a24922e05048bc270230f5\n-nodes.Attribute._infer = decorators.raise_if_nothing_inferred(\n-    decorators.path_wrapper(infer_attribute)\n-)\n-# won't work with a path wrapper\n-nodes.AssignAttr.infer_lhs = decorators.raise_if_nothing_inferred(infer_attribute)\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_global(\n-    self: nodes.Global, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, None]:\n-    if context is None or context.lookupname is None:\n-        raise InferenceError(node=self, context=context)\n-    try:\n-        return bases._infer_stmts(self.root().getattr(context.lookupname), context)\n-    except AttributeInferenceError as error:\n-        raise InferenceError(\n-            str(error), target=self, attribute=context.lookupname, context=context\n-        ) from error\n-\n-\n-nodes.Global._infer = infer_global  # type: ignore[assignment]\n-\n-\n-_SUBSCRIPT_SENTINEL = object()\n-\n-\n-def infer_subscript(\n-    self: nodes.Subscript, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n-    \"\"\"Inference for subscripts.\n-\n-    We're understanding if the index is a Const\n-    or a slice, passing the result of inference\n-    to the value's `getitem` method, which should\n-    handle each supported index type accordingly.\n-    \"\"\"\n-\n-    found_one = False\n-    for value in self.value.infer(context):\n-        if isinstance(value, util.UninferableBase):\n-            yield util.Uninferable\n-            return None\n-        for index in self.slice.infer(context):\n-            if isinstance(index, util.UninferableBase):\n-                yield util.Uninferable\n-                return None\n-\n-            # Try to deduce the index value.\n-            index_value = _SUBSCRIPT_SENTINEL\n-            if value.__class__ == bases.Instance:\n-                index_value = index\n-            elif index.__class__ == bases.Instance:\n-                instance_as_index = helpers.class_instance_as_index(index)\n-                if instance_as_index:\n-                    index_value = instance_as_index\n-            else:\n-                index_value = index\n-\n-            if index_value is _SUBSCRIPT_SENTINEL:\n-                raise InferenceError(node=self, context=context)\n-\n-            try:\n-                assigned = value.getitem(index_value, context)\n-            except (\n-                AstroidTypeError,\n-                AstroidIndexError,\n-                AstroidValueError,\n-                AttributeInferenceError,\n-                AttributeError,\n-            ) as exc:\n-                raise InferenceError(node=self, context=context) from exc\n-\n-            # Prevent inferring if the inferred subscript\n-            # is the same as the original subscripted object.\n-            if self is assigned or isinstance(assigned, util.UninferableBase):\n-                yield util.Uninferable\n-                return None\n-            yield from assigned.infer(context)\n-            found_one = True\n-\n-    if found_one:\n-        return InferenceErrorInfo(node=self, context=context)\n-    return None\n-\n-\n-# The order of the decorators here is important\n-# See https://github.com/pylint-dev/astroid/commit/0a8a75db30da060a24922e05048bc270230f5\n-nodes.Subscript._infer = decorators.raise_if_nothing_inferred(  # type: ignore[assignment]\n-    decorators.path_wrapper(infer_subscript)\n-)\n-nodes.Subscript.infer_lhs = decorators.raise_if_nothing_inferred(infer_subscript)\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def _infer_boolop(\n-    self: nodes.BoolOp, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n-    \"\"\"Infer a boolean operation (and / or / not).\n-\n-    The function will calculate the boolean operation\n-    for all pairs generated through inference for each component\n-    node.\n-    \"\"\"\n-    values = self.values\n-    if self.op == \"or\":\n-        predicate = operator.truth\n-    else:\n-        predicate = operator.not_\n-\n-    try:\n-        inferred_values = [value.infer(context=context) for value in values]\n-    except InferenceError:\n-        yield util.Uninferable\n-        return None\n-\n-    for pair in itertools.product(*inferred_values):\n-        if any(isinstance(item, util.UninferableBase) for item in pair):\n-            # Can't infer the final result, just yield Uninferable.\n-            yield util.Uninferable\n-            continue\n-\n-        bool_values = [item.bool_value() for item in pair]\n-        if any(isinstance(item, util.UninferableBase) for item in bool_values):\n-            # Can't infer the final result, just yield Uninferable.\n-            yield util.Uninferable\n-            continue\n-\n-        # Since the boolean operations are short circuited operations,\n-        # this code yields the first value for which the predicate is True\n-        # and if no value respected the predicate, then the last value will\n-        # be returned (or Uninferable if there was no last value).\n-        # This is conforming to the semantics of `and` and `or`:\n-        #   1 and 0 -> 1\n-        #   0 and 1 -> 0\n-        #   1 or 0 -> 1\n-        #   0 or 1 -> 1\n-        value = util.Uninferable\n-        for value, bool_value in zip(pair, bool_values):\n-            if predicate(bool_value):\n-                yield value\n-                break\n-        else:\n-            yield value\n-\n-    return InferenceErrorInfo(node=self, context=context)\n-\n-\n-nodes.BoolOp._infer = _infer_boolop\n-\n-\n-# UnaryOp, BinOp and AugAssign inferences\n-\n-\n-def _filter_operation_errors(\n-    self: _T,\n-    infer_callable: Callable[\n-        [_T, InferenceContext | None],\n-        Generator[InferenceResult | util.BadOperationMessage, None, None],\n-    ],\n-    context: InferenceContext | None,\n-    error: type[util.BadOperationMessage],\n-) -> Generator[InferenceResult, None, None]:\n-    for result in infer_callable(self, context):\n-        if isinstance(result, error):\n-            # For the sake of .infer(), we don't care about operation\n-            # errors, which is the job of pylint. So return something\n-            # which shows that we can't infer the result.\n-            yield util.Uninferable\n-        else:\n-            yield result\n-\n-\n-def _infer_unaryop(\n-    self: nodes.UnaryOp, context: InferenceContext | None = None\n-) -> Generator[InferenceResult | util.BadUnaryOperationMessage, None, None]:\n-    \"\"\"Infer what an UnaryOp should return when evaluated.\"\"\"\n-    for operand in self.operand.infer(context):\n-        try:\n-            yield operand.infer_unary_op(self.op)\n-        except TypeError as exc:\n-            # The operand doesn't support this operation.\n-            yield util.BadUnaryOperationMessage(operand, self.op, exc)\n-        except AttributeError as exc:\n-            meth = protocols.UNARY_OP_METHOD[self.op]\n-            if meth is None:\n-                # `not node`. Determine node's boolean\n-                # value and negate its result, unless it is\n-                # Uninferable, which will be returned as is.\n-                bool_value = operand.bool_value()\n-                if not isinstance(bool_value, util.UninferableBase):\n-                    yield nodes.const_factory(not bool_value)\n-                else:\n-                    yield util.Uninferable\n-            else:\n-                if not isinstance(operand, (bases.Instance, nodes.ClassDef)):\n-                    # The operation was used on something which\n-                    # doesn't support it.\n-                    yield util.BadUnaryOperationMessage(operand, self.op, exc)\n-                    continue\n-\n-                try:\n-                    try:\n-                        methods = dunder_lookup.lookup(operand, meth)\n-                    except AttributeInferenceError:\n-                        yield util.BadUnaryOperationMessage(operand, self.op, exc)\n-                        continue\n-\n-                    meth = methods[0]\n-                    inferred = next(meth.infer(context=context), None)\n-                    if (\n-                        isinstance(inferred, util.UninferableBase)\n-                        or not inferred.callable()\n-                    ):\n-                        continue\n-\n-                    context = copy_context(context)\n-                    context.boundnode = operand\n-                    context.callcontext = CallContext(args=[], callee=inferred)\n-\n-                    call_results = inferred.infer_call_result(self, context=context)\n-                    result = next(call_results, None)\n-                    if result is None:\n-                        # Failed to infer, return the same type.\n-                        yield operand\n-                    else:\n-                        yield result\n-                except AttributeInferenceError as inner_exc:\n-                    # The unary operation special method was not found.\n-                    yield util.BadUnaryOperationMessage(operand, self.op, inner_exc)\n-                except InferenceError:\n-                    yield util.Uninferable\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_unaryop(\n-    self: nodes.UnaryOp, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, InferenceErrorInfo]:\n-    \"\"\"Infer what an UnaryOp should return when evaluated.\"\"\"\n-    yield from _filter_operation_errors(\n-        self, _infer_unaryop, context, util.BadUnaryOperationMessage\n-    )\n-    return InferenceErrorInfo(node=self, context=context)\n-\n-\n-nodes.UnaryOp._infer_unaryop = _infer_unaryop\n-nodes.UnaryOp._infer = infer_unaryop\n-\n-\n-def _is_not_implemented(const) -> bool:\n-    \"\"\"Check if the given const node is NotImplemented.\"\"\"\n-    return isinstance(const, nodes.Const) and const.value is NotImplemented\n-\n-\n-def _infer_old_style_string_formatting(\n-    instance: nodes.Const, other: nodes.NodeNG, context: InferenceContext\n-) -> tuple[util.UninferableBase | nodes.Const]:\n-    \"\"\"Infer the result of '\"string\" % ...'.\n-\n-    TODO: Instead of returning Uninferable we should rely\n-    on the call to '%' to see if the result is actually uninferable.\n-    \"\"\"\n-    if isinstance(other, nodes.Tuple):\n-        if util.Uninferable in other.elts:\n-            return (util.Uninferable,)\n-        inferred_positional = [helpers.safe_infer(i, context) for i in other.elts]\n-        if all(isinstance(i, nodes.Const) for i in inferred_positional):\n-            values = tuple(i.value for i in inferred_positional)\n-        else:\n-            values = None\n-    elif isinstance(other, nodes.Dict):\n-        values: dict[Any, Any] = {}\n-        for pair in other.items:\n-            key = helpers.safe_infer(pair[0], context)\n-            if not isinstance(key, nodes.Const):\n-                return (util.Uninferable,)\n-            value = helpers.safe_infer(pair[1], context)\n-            if not isinstance(value, nodes.Const):\n-                return (util.Uninferable,)\n-            values[key.value] = value.value\n-    elif isinstance(other, nodes.Const):\n-        values = other.value\n-    else:\n-        return (util.Uninferable,)\n-\n-    try:\n-        return (nodes.const_factory(instance.value % values),)\n-    except (TypeError, KeyError, ValueError):\n-        return (util.Uninferable,)\n-\n-\n-def _invoke_binop_inference(\n-    instance: InferenceResult,\n-    opnode: nodes.AugAssign | nodes.BinOp,\n-    op: str,\n-    other: InferenceResult,\n-    context: InferenceContext,\n-    method_name: str,\n-) -> Generator[InferenceResult, None, None]:\n-    \"\"\"Invoke binary operation inference on the given instance.\"\"\"\n-    methods = dunder_lookup.lookup(instance, method_name)\n-    context = bind_context_to_node(context, instance)\n-    method = methods[0]\n-    context.callcontext.callee = method\n-\n-    if (\n-        isinstance(instance, nodes.Const)\n-        and isinstance(instance.value, str)\n-        and op == \"%\"\n-    ):\n-        return iter(_infer_old_style_string_formatting(instance, other, context))\n-\n-    try:\n-        inferred = next(method.infer(context=context))\n-    except StopIteration as e:\n-        raise InferenceError(node=method, context=context) from e\n-    if isinstance(inferred, util.UninferableBase):\n-        raise InferenceError\n-    if not isinstance(\n-        instance, (nodes.Const, nodes.Tuple, nodes.List, nodes.ClassDef, bases.Instance)\n-    ):\n-        raise InferenceError  # pragma: no cover # Used as a failsafe\n-    return instance.infer_binary_op(opnode, op, other, context, inferred)\n-\n-\n-def _aug_op(\n-    instance: InferenceResult,\n-    opnode: nodes.AugAssign,\n-    op: str,\n-    other: InferenceResult,\n-    context: InferenceContext,\n-    reverse: bool = False,\n-) -> functools.partial[Generator[InferenceResult, None, None]]:\n-    \"\"\"Get an inference callable for an augmented binary operation.\"\"\"\n-    method_name = protocols.AUGMENTED_OP_METHOD[op]\n-    return functools.partial(\n-        _invoke_binop_inference,\n-        instance=instance,\n-        op=op,\n-        opnode=opnode,\n-        other=other,\n-        context=context,\n-        method_name=method_name,\n-    )\n-\n-\n-def _bin_op(\n-    instance: InferenceResult,\n-    opnode: nodes.AugAssign | nodes.BinOp,\n-    op: str,\n-    other: InferenceResult,\n-    context: InferenceContext,\n-    reverse: bool = False,\n-) -> functools.partial[Generator[InferenceResult, None, None]]:\n-    \"\"\"Get an inference callable for a normal binary operation.\n-\n-    If *reverse* is True, then the reflected method will be used instead.\n-    \"\"\"\n-    if reverse:\n-        method_name = protocols.REFLECTED_BIN_OP_METHOD[op]\n-    else:\n-        method_name = protocols.BIN_OP_METHOD[op]\n-    return functools.partial(\n-        _invoke_binop_inference,\n-        instance=instance,\n-        op=op,\n-        opnode=opnode,\n-        other=other,\n-        context=context,\n-        method_name=method_name,\n-    )\n-\n-\n-def _bin_op_or_union_type(\n-    left: bases.UnionType | nodes.ClassDef | nodes.Const,\n-    right: bases.UnionType | nodes.ClassDef | nodes.Const,\n-) -> Generator[InferenceResult, None, None]:\n-    \"\"\"Create a new UnionType instance for binary or, e.g. int | str.\"\"\"\n-    yield bases.UnionType(left, right)\n-\n-\n-def _get_binop_contexts(context, left, right):\n-    \"\"\"Get contexts for binary operations.\n-\n-    This will return two inference contexts, the first one\n-    for x.__op__(y), the other one for y.__rop__(x), where\n-    only the arguments are inversed.\n-    \"\"\"\n-    # The order is important, since the first one should be\n-    # left.__op__(right).\n-    for arg in (right, left):\n-        new_context = context.clone()\n-        new_context.callcontext = CallContext(args=[arg])\n-        new_context.boundnode = None\n-        yield new_context\n-\n-\n-def _same_type(type1, type2) -> bool:\n-    \"\"\"Check if type1 is the same as type2.\"\"\"\n-    return type1.qname() == type2.qname()\n-\n-\n-def _get_binop_flow(\n-    left: InferenceResult,\n-    left_type: InferenceResult | None,\n-    binary_opnode: nodes.AugAssign | nodes.BinOp,\n-    right: InferenceResult,\n-    right_type: InferenceResult | None,\n-    context: InferenceContext,\n-    reverse_context: InferenceContext,\n-) -> list[functools.partial[Generator[InferenceResult, None, None]]]:\n-    \"\"\"Get the flow for binary operations.\n-\n-    The rules are a bit messy:\n-\n-        * if left and right have the same type, then only one\n-          method will be called, left.__op__(right)\n-        * if left and right are unrelated typewise, then first\n-          left.__op__(right) is tried and if this does not exist\n-          or returns NotImplemented, then right.__rop__(left) is tried.\n-        * if left is a subtype of right, then only left.__op__(right)\n-          is tried.\n-        * if left is a supertype of right, then right.__rop__(left)\n-          is first tried and then left.__op__(right)\n-    \"\"\"\n-    op = binary_opnode.op\n-    if _same_type(left_type, right_type):\n-        methods = [_bin_op(left, binary_opnode, op, right, context)]\n-    elif helpers.is_subtype(left_type, right_type):\n-        methods = [_bin_op(left, binary_opnode, op, right, context)]\n-    elif helpers.is_supertype(left_type, right_type):\n-        methods = [\n-            _bin_op(right, binary_opnode, op, left, reverse_context, reverse=True),\n-            _bin_op(left, binary_opnode, op, right, context),\n-        ]\n-    else:\n-        methods = [\n-            _bin_op(left, binary_opnode, op, right, context),\n-            _bin_op(right, binary_opnode, op, left, reverse_context, reverse=True),\n-        ]\n-\n-    if (\n-        PY310_PLUS\n-        and op == \"|\"\n-        and (\n-            isinstance(left, (bases.UnionType, nodes.ClassDef))\n-            or isinstance(left, nodes.Const)\n-            and left.value is None\n-        )\n-        and (\n-            isinstance(right, (bases.UnionType, nodes.ClassDef))\n-            or isinstance(right, nodes.Const)\n-            and right.value is None\n-        )\n-    ):\n-        methods.extend([functools.partial(_bin_op_or_union_type, left, right)])\n-    return methods\n-\n-\n-def _get_aug_flow(\n-    left: InferenceResult,\n-    left_type: InferenceResult | None,\n-    aug_opnode: nodes.AugAssign,\n-    right: InferenceResult,\n-    right_type: InferenceResult | None,\n-    context: InferenceContext,\n-    reverse_context: InferenceContext,\n-) -> list[functools.partial[Generator[InferenceResult, None, None]]]:\n-    \"\"\"Get the flow for augmented binary operations.\n-\n-    The rules are a bit messy:\n-\n-        * if left and right have the same type, then left.__augop__(right)\n-          is first tried and then left.__op__(right).\n-        * if left and right are unrelated typewise, then\n-          left.__augop__(right) is tried, then left.__op__(right)\n-          is tried and then right.__rop__(left) is tried.\n-        * if left is a subtype of right, then left.__augop__(right)\n-          is tried and then left.__op__(right).\n-        * if left is a supertype of right, then left.__augop__(right)\n-          is tried, then right.__rop__(left) and then\n-          left.__op__(right)\n-    \"\"\"\n-    bin_op = aug_opnode.op.strip(\"=\")\n-    aug_op = aug_opnode.op\n-    if _same_type(left_type, right_type):\n-        methods = [\n-            _aug_op(left, aug_opnode, aug_op, right, context),\n-            _bin_op(left, aug_opnode, bin_op, right, context),\n-        ]\n-    elif helpers.is_subtype(left_type, right_type):\n-        methods = [\n-            _aug_op(left, aug_opnode, aug_op, right, context),\n-            _bin_op(left, aug_opnode, bin_op, right, context),\n-        ]\n-    elif helpers.is_supertype(left_type, right_type):\n-        methods = [\n-            _aug_op(left, aug_opnode, aug_op, right, context),\n-            _bin_op(right, aug_opnode, bin_op, left, reverse_context, reverse=True),\n-            _bin_op(left, aug_opnode, bin_op, right, context),\n-        ]\n-    else:\n-        methods = [\n-            _aug_op(left, aug_opnode, aug_op, right, context),\n-            _bin_op(left, aug_opnode, bin_op, right, context),\n-            _bin_op(right, aug_opnode, bin_op, left, reverse_context, reverse=True),\n-        ]\n-    return methods\n-\n-\n-def _infer_binary_operation(\n-    left: InferenceResult,\n-    right: InferenceResult,\n-    binary_opnode: nodes.AugAssign | nodes.BinOp,\n-    context: InferenceContext,\n-    flow_factory: GetFlowFactory,\n-) -> Generator[InferenceResult | util.BadBinaryOperationMessage, None, None]:\n-    \"\"\"Infer a binary operation between a left operand and a right operand.\n-\n-    This is used by both normal binary operations and augmented binary\n-    operations, the only difference is the flow factory used.\n-    \"\"\"\n-\n-    context, reverse_context = _get_binop_contexts(context, left, right)\n-    left_type = helpers.object_type(left)\n-    right_type = helpers.object_type(right)\n-    methods = flow_factory(\n-        left, left_type, binary_opnode, right, right_type, context, reverse_context\n-    )\n-    for method in methods:\n-        try:\n-            results = list(method())\n-        except AttributeError:\n-            continue\n-        except AttributeInferenceError:\n-            continue\n-        except InferenceError:\n-            yield util.Uninferable\n-            return\n-        else:\n-            if any(isinstance(result, util.UninferableBase) for result in results):\n-                yield util.Uninferable\n-                return\n-\n-            if all(map(_is_not_implemented, results)):\n-                continue\n-            not_implemented = sum(\n-                1 for result in results if _is_not_implemented(result)\n-            )\n-            if not_implemented and not_implemented != len(results):\n-                # Can't infer yet what this is.\n-                yield util.Uninferable\n-                return\n-\n-            yield from results\n-            return\n-    # The operation doesn't seem to be supported so let the caller know about it\n-    yield util.BadBinaryOperationMessage(left_type, binary_opnode.op, right_type)\n-\n-\n-def _infer_binop(\n-    self: nodes.BinOp, context: InferenceContext | None = None\n-) -> Generator[InferenceResult | util.BadBinaryOperationMessage, None, None]:\n-    \"\"\"Binary operation inference logic.\"\"\"\n-    left = self.left\n-    right = self.right\n-\n-    # we use two separate contexts for evaluating lhs and rhs because\n-    # 1. evaluating lhs may leave some undesired entries in context.path\n-    #    which may not let us infer right value of rhs\n-    context = context or InferenceContext()\n-    lhs_context = copy_context(context)\n-    rhs_context = copy_context(context)\n-    lhs_iter = left.infer(context=lhs_context)\n-    rhs_iter = right.infer(context=rhs_context)\n-    for lhs, rhs in itertools.product(lhs_iter, rhs_iter):\n-        if any(isinstance(value, util.UninferableBase) for value in (rhs, lhs)):\n-            # Don't know how to process this.\n-            yield util.Uninferable\n-            return\n-\n-        try:\n-            yield from _infer_binary_operation(lhs, rhs, self, context, _get_binop_flow)\n-        except _NonDeducibleTypeHierarchy:\n-            yield util.Uninferable\n-\n-\n-@decorators.yes_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_binop(\n-    self: nodes.BinOp, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, None]:\n-    return _filter_operation_errors(\n-        self, _infer_binop, context, util.BadBinaryOperationMessage\n-    )\n-\n-\n-nodes.BinOp._infer_binop = _infer_binop\n-nodes.BinOp._infer = infer_binop\n-\n-COMPARE_OPS: dict[str, Callable[[Any, Any], bool]] = {\n-    \"==\": operator.eq,\n-    \"!=\": operator.ne,\n-    \"<\": operator.lt,\n-    \"<=\": operator.le,\n-    \">\": operator.gt,\n-    \">=\": operator.ge,\n-    \"in\": lambda a, b: a in b,\n-    \"not in\": lambda a, b: a not in b,\n-}\n-UNINFERABLE_OPS = {\n-    \"is\",\n-    \"is not\",\n-}\n-\n-\n-def _to_literal(node: SuccessfulInferenceResult) -> Any:\n-    # Can raise SyntaxError or ValueError from ast.literal_eval\n-    # Can raise AttributeError from node.as_string() as not all nodes have a visitor\n-    # Is this the stupidest idea or the simplest idea?\n-    return ast.literal_eval(node.as_string())\n-\n-\n-def _do_compare(\n-    left_iter: Iterable[InferenceResult], op: str, right_iter: Iterable[InferenceResult]\n-) -> bool | util.UninferableBase:\n-    \"\"\"\n-    If all possible combinations are either True or False, return that:\n-    >>> _do_compare([1, 2], '<=', [3, 4])\n-    True\n-    >>> _do_compare([1, 2], '==', [3, 4])\n-    False\n-\n-    If any item is uninferable, or if some combinations are True and some\n-    are False, return Uninferable:\n-    >>> _do_compare([1, 3], '<=', [2, 4])\n-    util.Uninferable\n-    \"\"\"\n-    retval: bool | None = None\n-    if op in UNINFERABLE_OPS:\n-        return util.Uninferable\n-    op_func = COMPARE_OPS[op]\n-\n-    for left, right in itertools.product(left_iter, right_iter):\n-        if isinstance(left, util.UninferableBase) or isinstance(\n-            right, util.UninferableBase\n-        ):\n-            return util.Uninferable\n-\n-        try:\n-            left, right = _to_literal(left), _to_literal(right)\n-        except (SyntaxError, ValueError, AttributeError):\n-            return util.Uninferable\n-\n-        try:\n-            expr = op_func(left, right)\n-        except TypeError as exc:\n-            raise AstroidTypeError from exc\n-\n-        if retval is None:\n-            retval = expr\n-        elif retval != expr:\n-            return util.Uninferable\n-            # (or both, but \"True | False\" is basically the same)\n-\n-    assert retval is not None\n-    return retval  # it was all the same value\n-\n-\n-def _infer_compare(\n-    self: nodes.Compare, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[nodes.Const | util.UninferableBase, None, None]:\n-    \"\"\"Chained comparison inference logic.\"\"\"\n-    retval: bool | util.UninferableBase = True\n-\n-    ops = self.ops\n-    left_node = self.left\n-    lhs = list(left_node.infer(context=context))\n-    # should we break early if first element is uninferable?\n-    for op, right_node in ops:\n-        # eagerly evaluate rhs so that values can be re-used as lhs\n-        rhs = list(right_node.infer(context=context))\n-        try:\n-            retval = _do_compare(lhs, op, rhs)\n-        except AstroidTypeError:\n-            retval = util.Uninferable\n-            break\n-        if retval is not True:\n-            break  # short-circuit\n-        lhs = rhs  # continue\n-    if retval is util.Uninferable:\n-        yield retval  # type: ignore[misc]\n-    else:\n-        yield nodes.Const(retval)\n-\n-\n-nodes.Compare._infer = _infer_compare  # type: ignore[assignment]\n-\n-\n-def _infer_augassign(\n-    self: nodes.AugAssign, context: InferenceContext | None = None\n-) -> Generator[InferenceResult | util.BadBinaryOperationMessage, None, None]:\n-    \"\"\"Inference logic for augmented binary operations.\"\"\"\n-    context = context or InferenceContext()\n-\n-    rhs_context = context.clone()\n-\n-    lhs_iter = self.target.infer_lhs(context=context)\n-    rhs_iter = self.value.infer(context=rhs_context)\n-    for lhs, rhs in itertools.product(lhs_iter, rhs_iter):\n-        if any(isinstance(value, util.UninferableBase) for value in (rhs, lhs)):\n-            # Don't know how to process this.\n-            yield util.Uninferable\n-            return\n-\n-        try:\n-            yield from _infer_binary_operation(\n-                left=lhs,\n-                right=rhs,\n-                binary_opnode=self,\n-                context=context,\n-                flow_factory=_get_aug_flow,\n-            )\n-        except _NonDeducibleTypeHierarchy:\n-            yield util.Uninferable\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_augassign(\n-    self: nodes.AugAssign, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, None]:\n-    return _filter_operation_errors(\n-        self, _infer_augassign, context, util.BadBinaryOperationMessage\n-    )\n-\n-\n-nodes.AugAssign._infer_augassign = _infer_augassign\n-nodes.AugAssign._infer = infer_augassign\n-\n-# End of binary operation inference.\n-\n-\n-@decorators.raise_if_nothing_inferred\n-def infer_arguments(\n-    self: nodes.Arguments, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, None]:\n-    if context is None or context.lookupname is None:\n-        raise InferenceError(node=self, context=context)\n-    return protocols._arguments_infer_argname(self, context.lookupname, context)\n-\n-\n-nodes.Arguments._infer = infer_arguments  # type: ignore[assignment]\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_assign(\n-    self: nodes.AssignName | nodes.AssignAttr,\n-    context: InferenceContext | None = None,\n-    **kwargs: Any,\n-) -> Generator[InferenceResult, None, None]:\n-    \"\"\"Infer a AssignName/AssignAttr: need to inspect the RHS part of the\n-    assign node.\n-    \"\"\"\n-    if isinstance(self.parent, nodes.AugAssign):\n-        return self.parent.infer(context)\n-\n-    stmts = list(self.assigned_stmts(context=context))\n-    return bases._infer_stmts(stmts, context)\n-\n-\n-nodes.AssignName._infer = infer_assign\n-nodes.AssignAttr._infer = infer_assign\n-\n-\n-@decorators.raise_if_nothing_inferred\n-@decorators.path_wrapper\n-def infer_empty_node(\n-    self: nodes.EmptyNode, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, None]:\n-    if not self.has_underlying_object():\n-        yield util.Uninferable\n-    else:\n-        try:\n-            yield from AstroidManager().infer_ast_from_something(\n-                self.object, context=context\n-            )\n-        except AstroidError:\n-            yield util.Uninferable\n-\n-\n-nodes.EmptyNode._infer = infer_empty_node  # type: ignore[assignment]\n-\n-\n-def _populate_context_lookup(call: nodes.Call, context: InferenceContext | None):\n-    # Allows context to be saved for later\n-    # for inference inside a function\n-    context_lookup: dict[InferenceResult, InferenceContext] = {}\n-    if context is None:\n-        return context_lookup\n-    for arg in call.args:\n-        if isinstance(arg, nodes.Starred):\n-            context_lookup[arg.value] = context\n-        else:\n-            context_lookup[arg] = context\n-    keywords = call.keywords if call.keywords is not None else []\n-    for keyword in keywords:\n-        context_lookup[keyword.value] = context\n-    return context_lookup\n-\n-\n-@decorators.raise_if_nothing_inferred\n-def infer_ifexp(\n-    self: nodes.IfExp, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[InferenceResult, None, None]:\n-    \"\"\"Support IfExp inference.\n-\n-    If we can't infer the truthiness of the condition, we default\n-    to inferring both branches. Otherwise, we infer either branch\n-    depending on the condition.\n-    \"\"\"\n-    both_branches = False\n-    # We use two separate contexts for evaluating lhs and rhs because\n-    # evaluating lhs may leave some undesired entries in context.path\n-    # which may not let us infer right value of rhs.\n-\n-    context = context or InferenceContext()\n-    lhs_context = copy_context(context)\n-    rhs_context = copy_context(context)\n-    try:\n-        test = next(self.test.infer(context=context.clone()))\n-    except (InferenceError, StopIteration):\n-        both_branches = True\n-    else:\n-        if not isinstance(test, util.UninferableBase):\n-            if test.bool_value():\n-                yield from self.body.infer(context=lhs_context)\n-            else:\n-                yield from self.orelse.infer(context=rhs_context)\n-        else:\n-            both_branches = True\n-    if both_branches:\n-        yield from self.body.infer(context=lhs_context)\n-        yield from self.orelse.infer(context=rhs_context)\n-\n-\n-nodes.IfExp._infer = infer_ifexp  # type: ignore[assignment]\n-\n-\n-def infer_functiondef(\n-    self: _FunctionDefT, context: InferenceContext | None = None, **kwargs: Any\n-) -> Generator[Property | _FunctionDefT, None, InferenceErrorInfo]:\n-    if not self.decorators or not bases._is_property(self):\n-        yield self\n-        return InferenceErrorInfo(node=self, context=context)\n-\n-    # When inferring a property, we instantiate a new `objects.Property` object,\n-    # which in turn, because it inherits from `FunctionDef`, sets itself in the locals\n-    # of the wrapping frame. This means that every time we infer a property, the locals\n-    # are mutated with a new instance of the property. To avoid this, we detect this\n-    # scenario and avoid passing the `parent` argument to the constructor.\n-    parent_frame = self.parent.frame()\n-    property_already_in_parent_locals = self.name in parent_frame.locals and any(\n-        isinstance(val, objects.Property) for val in parent_frame.locals[self.name]\n-    )\n-    # We also don't want to pass parent if the definition is within a Try node\n-    if isinstance(self.parent, (nodes.TryExcept, nodes.TryFinally, nodes.If)):\n-        property_already_in_parent_locals = True\n-\n-    prop_func = objects.Property(\n-        function=self,\n-        name=self.name,\n-        lineno=self.lineno,\n-        parent=self.parent if not property_already_in_parent_locals else None,\n-        col_offset=self.col_offset,\n-    )\n-    if property_already_in_parent_locals:\n-        prop_func.parent = self.parent\n-    prop_func.postinit(body=[], args=self.args, doc_node=self.doc_node)\n-    yield prop_func\n-    return InferenceErrorInfo(node=self, context=context)\n-\n-\n-nodes.FunctionDef._infer = infer_functiondef\ndiff --git a/astroid/manager.py b/astroid/manager.py\nindex 2df270f1ac..2d0903fe53 100644\n--- a/astroid/manager.py\n+++ b/astroid/manager.py\n@@ -434,7 +434,7 @@ def clear_cache(self) -> None:\n         # pylint: disable=import-outside-toplevel\n         from astroid.inference_tip import clear_inference_tip_cache\n         from astroid.interpreter.objectmodel import ObjectModel\n-        from astroid.nodes.node_classes import LookupMixIn\n+        from astroid.nodes._base_nodes import LookupMixIn\n         from astroid.nodes.scoped_nodes import ClassDef\n \n         clear_inference_tip_cache()\ndiff --git a/astroid/node_classes.py b/astroid/node_classes.py\nindex 980fa0a90b..7f3614e46b 100644\n--- a/astroid/node_classes.py\n+++ b/astroid/node_classes.py\n@@ -48,7 +48,6 @@\n     JoinedStr,\n     Keyword,\n     List,\n-    LookupMixIn,\n     Match,\n     MatchAs,\n     MatchCase,\ndiff --git a/astroid/nodes/__init__.py b/astroid/nodes/__init__.py\nindex 84fcb521f2..44712f1074 100644\n--- a/astroid/nodes/__init__.py\n+++ b/astroid/nodes/__init__.py\n@@ -11,10 +11,6 @@\n \"\"\"\n \n # Nodes not present in the builtin ast module:  DictUnpack, Unknown, and EvaluatedObject.\n-\n-# This is the only node we re-export from the private _base_nodes module. This\n-# is because it was originally part of the public API and hasn't been deprecated.\n-from astroid.nodes._base_nodes import Statement\n from astroid.nodes.node_classes import (\n     CONST_CLS,\n     AnnAssign,\n@@ -115,10 +111,7 @@\n )\n from astroid.nodes.utils import Position\n \n-_BaseContainer = BaseContainer  # TODO Remove for astroid 3.0\n-\n ALL_NODE_CLASSES = (\n-    _BaseContainer,\n     BaseContainer,\n     AnnAssign,\n     Arguments,\n@@ -223,6 +216,7 @@\n     \"Attribute\",\n     \"AugAssign\",\n     \"Await\",\n+    \"BaseContainer\",\n     \"BinOp\",\n     \"BoolOp\",\n     \"Break\",\n@@ -288,7 +282,6 @@\n     \"SetComp\",\n     \"Slice\",\n     \"Starred\",\n-    \"Statement\",\n     \"Subscript\",\n     \"TryExcept\",\n     \"TryFinally\",\ndiff --git a/astroid/nodes/_base_nodes.py b/astroid/nodes/_base_nodes.py\nindex 15cc6a9ad1..d6d80986a9 100644\n--- a/astroid/nodes/_base_nodes.py\n+++ b/astroid/nodes/_base_nodes.py\n@@ -10,15 +10,42 @@\n from __future__ import annotations\n \n import itertools\n-from collections.abc import Iterator\n-from functools import cached_property\n-from typing import TYPE_CHECKING, ClassVar\n-\n-from astroid.exceptions import AttributeInferenceError\n+from collections.abc import Generator, Iterator\n+from functools import cached_property, lru_cache, partial\n+from typing import TYPE_CHECKING, Any, Callable, ClassVar, Optional, Union\n+\n+from astroid import bases, decorators, nodes, util\n+from astroid.const import PY310_PLUS\n+from astroid.context import (\n+    CallContext,\n+    InferenceContext,\n+    bind_context_to_node,\n+    copy_context,\n+)\n+from astroid.exceptions import (\n+    AttributeInferenceError,\n+    InferenceError,\n+    NameInferenceError,\n+)\n+from astroid.interpreter import dunder_lookup\n from astroid.nodes.node_ng import NodeNG\n+from astroid.typing import InferenceErrorInfo, InferenceResult\n \n if TYPE_CHECKING:\n-    from astroid import nodes\n+    from astroid.nodes.node_classes import AssignedStmtsPossibleNode, LocalsDictNodeNG\n+\n+    GetFlowFactory = Callable[\n+        [\n+            InferenceResult,\n+            Optional[InferenceResult],\n+            Union[nodes.AugAssign, nodes.BinOp],\n+            InferenceResult,\n+            Optional[InferenceResult],\n+            InferenceContext,\n+            InferenceContext,\n+        ],\n+        list[partial[Generator[InferenceResult, None, None]]],\n+    ]\n \n \n class Statement(NodeNG):\n@@ -223,3 +250,526 @@ def _elsed_block_range(\n                 return lineno, orelse[-1].tolineno\n             return lineno, orelse[0].fromlineno - 1\n         return lineno, last or self.tolineno\n+\n+\n+class LookupMixIn(NodeNG):\n+    \"\"\"Mixin to look up a name in the right scope.\"\"\"\n+\n+    @lru_cache  # noqa\n+    def lookup(self, name: str) -> tuple[LocalsDictNodeNG, list[NodeNG]]:\n+        \"\"\"Lookup where the given variable is assigned.\n+\n+        The lookup starts from self's scope. If self is not a frame itself\n+        and the name is found in the inner frame locals, statements will be\n+        filtered to remove ignorable statements according to self's location.\n+\n+        :param name: The name of the variable to find assignments for.\n+\n+        :returns: The scope node and the list of assignments associated to the\n+            given name according to the scope where it has been found (locals,\n+            globals or builtin).\n+        \"\"\"\n+        return self.scope().scope_lookup(self, name)\n+\n+    def ilookup(self, name):\n+        \"\"\"Lookup the inferred values of the given variable.\n+\n+        :param name: The variable name to find values for.\n+        :type name: str\n+\n+        :returns: The inferred values of the statements returned from\n+            :meth:`lookup`.\n+        :rtype: iterable\n+        \"\"\"\n+        frame, stmts = self.lookup(name)\n+        context = InferenceContext()\n+        return bases._infer_stmts(stmts, context, frame)\n+\n+\n+def _reflected_name(name) -> str:\n+    return \"__r\" + name[2:]\n+\n+\n+def _augmented_name(name) -> str:\n+    return \"__i\" + name[2:]\n+\n+\n+BIN_OP_METHOD = {\n+    \"+\": \"__add__\",\n+    \"-\": \"__sub__\",\n+    \"/\": \"__truediv__\",\n+    \"//\": \"__floordiv__\",\n+    \"*\": \"__mul__\",\n+    \"**\": \"__pow__\",\n+    \"%\": \"__mod__\",\n+    \"&\": \"__and__\",\n+    \"|\": \"__or__\",\n+    \"^\": \"__xor__\",\n+    \"<<\": \"__lshift__\",\n+    \">>\": \"__rshift__\",\n+    \"@\": \"__matmul__\",\n+}\n+\n+REFLECTED_BIN_OP_METHOD = {\n+    key: _reflected_name(value) for (key, value) in BIN_OP_METHOD.items()\n+}\n+AUGMENTED_OP_METHOD = {\n+    key + \"=\": _augmented_name(value) for (key, value) in BIN_OP_METHOD.items()\n+}\n+\n+\n+class OperatorNode(NodeNG):\n+    @staticmethod\n+    def _filter_operation_errors(\n+        infer_callable: Callable[\n+            [InferenceContext | None],\n+            Generator[InferenceResult | util.BadOperationMessage, None, None],\n+        ],\n+        context: InferenceContext | None,\n+        error: type[util.BadOperationMessage],\n+    ) -> Generator[InferenceResult, None, None]:\n+        for result in infer_callable(context):\n+            if isinstance(result, error):\n+                # For the sake of .infer(), we don't care about operation\n+                # errors, which is the job of pylint. So return something\n+                # which shows that we can't infer the result.\n+                yield util.Uninferable\n+            else:\n+                yield result\n+\n+    @staticmethod\n+    def _is_not_implemented(const) -> bool:\n+        \"\"\"Check if the given const node is NotImplemented.\"\"\"\n+        return isinstance(const, nodes.Const) and const.value is NotImplemented\n+\n+    @staticmethod\n+    def _infer_old_style_string_formatting(\n+        instance: nodes.Const, other: nodes.NodeNG, context: InferenceContext\n+    ) -> tuple[util.UninferableBase | nodes.Const]:\n+        \"\"\"Infer the result of '\"string\" % ...'.\n+\n+        TODO: Instead of returning Uninferable we should rely\n+        on the call to '%' to see if the result is actually uninferable.\n+        \"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        if isinstance(other, nodes.Tuple):\n+            if util.Uninferable in other.elts:\n+                return (util.Uninferable,)\n+            inferred_positional = [helpers.safe_infer(i, context) for i in other.elts]\n+            if all(isinstance(i, nodes.Const) for i in inferred_positional):\n+                values = tuple(i.value for i in inferred_positional)\n+            else:\n+                values = None\n+        elif isinstance(other, nodes.Dict):\n+            values: dict[Any, Any] = {}\n+            for pair in other.items:\n+                key = helpers.safe_infer(pair[0], context)\n+                if not isinstance(key, nodes.Const):\n+                    return (util.Uninferable,)\n+                value = helpers.safe_infer(pair[1], context)\n+                if not isinstance(value, nodes.Const):\n+                    return (util.Uninferable,)\n+                values[key.value] = value.value\n+        elif isinstance(other, nodes.Const):\n+            values = other.value\n+        else:\n+            return (util.Uninferable,)\n+\n+        try:\n+            return (nodes.const_factory(instance.value % values),)\n+        except (TypeError, KeyError, ValueError):\n+            return (util.Uninferable,)\n+\n+    @staticmethod\n+    def _invoke_binop_inference(\n+        instance: InferenceResult,\n+        opnode: nodes.AugAssign | nodes.BinOp,\n+        op: str,\n+        other: InferenceResult,\n+        context: InferenceContext,\n+        method_name: str,\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Invoke binary operation inference on the given instance.\"\"\"\n+        methods = dunder_lookup.lookup(instance, method_name)\n+        context = bind_context_to_node(context, instance)\n+        method = methods[0]\n+        context.callcontext.callee = method\n+\n+        if (\n+            isinstance(instance, nodes.Const)\n+            and isinstance(instance.value, str)\n+            and op == \"%\"\n+        ):\n+            return iter(\n+                OperatorNode._infer_old_style_string_formatting(\n+                    instance, other, context\n+                )\n+            )\n+\n+        try:\n+            inferred = next(method.infer(context=context))\n+        except StopIteration as e:\n+            raise InferenceError(node=method, context=context) from e\n+        if isinstance(inferred, util.UninferableBase):\n+            raise InferenceError\n+        if not isinstance(\n+            instance,\n+            (nodes.Const, nodes.Tuple, nodes.List, nodes.ClassDef, bases.Instance),\n+        ):\n+            raise InferenceError  # pragma: no cover # Used as a failsafe\n+        return instance.infer_binary_op(opnode, op, other, context, inferred)\n+\n+    @staticmethod\n+    def _aug_op(\n+        instance: InferenceResult,\n+        opnode: nodes.AugAssign,\n+        op: str,\n+        other: InferenceResult,\n+        context: InferenceContext,\n+        reverse: bool = False,\n+    ) -> partial[Generator[InferenceResult, None, None]]:\n+        \"\"\"Get an inference callable for an augmented binary operation.\"\"\"\n+        method_name = AUGMENTED_OP_METHOD[op]\n+        return partial(\n+            OperatorNode._invoke_binop_inference,\n+            instance=instance,\n+            op=op,\n+            opnode=opnode,\n+            other=other,\n+            context=context,\n+            method_name=method_name,\n+        )\n+\n+    @staticmethod\n+    def _bin_op(\n+        instance: InferenceResult,\n+        opnode: nodes.AugAssign | nodes.BinOp,\n+        op: str,\n+        other: InferenceResult,\n+        context: InferenceContext,\n+        reverse: bool = False,\n+    ) -> partial[Generator[InferenceResult, None, None]]:\n+        \"\"\"Get an inference callable for a normal binary operation.\n+\n+        If *reverse* is True, then the reflected method will be used instead.\n+        \"\"\"\n+        if reverse:\n+            method_name = REFLECTED_BIN_OP_METHOD[op]\n+        else:\n+            method_name = BIN_OP_METHOD[op]\n+        return partial(\n+            OperatorNode._invoke_binop_inference,\n+            instance=instance,\n+            op=op,\n+            opnode=opnode,\n+            other=other,\n+            context=context,\n+            method_name=method_name,\n+        )\n+\n+    @staticmethod\n+    def _bin_op_or_union_type(\n+        left: bases.UnionType | nodes.ClassDef | nodes.Const,\n+        right: bases.UnionType | nodes.ClassDef | nodes.Const,\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Create a new UnionType instance for binary or, e.g. int | str.\"\"\"\n+        yield bases.UnionType(left, right)\n+\n+    @staticmethod\n+    def _get_binop_contexts(context, left, right):\n+        \"\"\"Get contexts for binary operations.\n+\n+        This will return two inference contexts, the first one\n+        for x.__op__(y), the other one for y.__rop__(x), where\n+        only the arguments are inversed.\n+        \"\"\"\n+        # The order is important, since the first one should be\n+        # left.__op__(right).\n+        for arg in (right, left):\n+            new_context = context.clone()\n+            new_context.callcontext = CallContext(args=[arg])\n+            new_context.boundnode = None\n+            yield new_context\n+\n+    @staticmethod\n+    def _same_type(type1, type2) -> bool:\n+        \"\"\"Check if type1 is the same as type2.\"\"\"\n+        return type1.qname() == type2.qname()\n+\n+    @staticmethod\n+    def _get_aug_flow(\n+        left: InferenceResult,\n+        left_type: InferenceResult | None,\n+        aug_opnode: nodes.AugAssign,\n+        right: InferenceResult,\n+        right_type: InferenceResult | None,\n+        context: InferenceContext,\n+        reverse_context: InferenceContext,\n+    ) -> list[partial[Generator[InferenceResult, None, None]]]:\n+        \"\"\"Get the flow for augmented binary operations.\n+\n+        The rules are a bit messy:\n+\n+            * if left and right have the same type, then left.__augop__(right)\n+            is first tried and then left.__op__(right).\n+            * if left and right are unrelated typewise, then\n+            left.__augop__(right) is tried, then left.__op__(right)\n+            is tried and then right.__rop__(left) is tried.\n+            * if left is a subtype of right, then left.__augop__(right)\n+            is tried and then left.__op__(right).\n+            * if left is a supertype of right, then left.__augop__(right)\n+            is tried, then right.__rop__(left) and then\n+            left.__op__(right)\n+        \"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        bin_op = aug_opnode.op.strip(\"=\")\n+        aug_op = aug_opnode.op\n+        if OperatorNode._same_type(left_type, right_type):\n+            methods = [\n+                OperatorNode._aug_op(left, aug_opnode, aug_op, right, context),\n+                OperatorNode._bin_op(left, aug_opnode, bin_op, right, context),\n+            ]\n+        elif helpers.is_subtype(left_type, right_type):\n+            methods = [\n+                OperatorNode._aug_op(left, aug_opnode, aug_op, right, context),\n+                OperatorNode._bin_op(left, aug_opnode, bin_op, right, context),\n+            ]\n+        elif helpers.is_supertype(left_type, right_type):\n+            methods = [\n+                OperatorNode._aug_op(left, aug_opnode, aug_op, right, context),\n+                OperatorNode._bin_op(\n+                    right, aug_opnode, bin_op, left, reverse_context, reverse=True\n+                ),\n+                OperatorNode._bin_op(left, aug_opnode, bin_op, right, context),\n+            ]\n+        else:\n+            methods = [\n+                OperatorNode._aug_op(left, aug_opnode, aug_op, right, context),\n+                OperatorNode._bin_op(left, aug_opnode, bin_op, right, context),\n+                OperatorNode._bin_op(\n+                    right, aug_opnode, bin_op, left, reverse_context, reverse=True\n+                ),\n+            ]\n+        return methods\n+\n+    @staticmethod\n+    def _get_binop_flow(\n+        left: InferenceResult,\n+        left_type: InferenceResult | None,\n+        binary_opnode: nodes.AugAssign | nodes.BinOp,\n+        right: InferenceResult,\n+        right_type: InferenceResult | None,\n+        context: InferenceContext,\n+        reverse_context: InferenceContext,\n+    ) -> list[partial[Generator[InferenceResult, None, None]]]:\n+        \"\"\"Get the flow for binary operations.\n+\n+        The rules are a bit messy:\n+\n+            * if left and right have the same type, then only one\n+            method will be called, left.__op__(right)\n+            * if left and right are unrelated typewise, then first\n+            left.__op__(right) is tried and if this does not exist\n+            or returns NotImplemented, then right.__rop__(left) is tried.\n+            * if left is a subtype of right, then only left.__op__(right)\n+            is tried.\n+            * if left is a supertype of right, then right.__rop__(left)\n+            is first tried and then left.__op__(right)\n+        \"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        op = binary_opnode.op\n+        if OperatorNode._same_type(left_type, right_type):\n+            methods = [OperatorNode._bin_op(left, binary_opnode, op, right, context)]\n+        elif helpers.is_subtype(left_type, right_type):\n+            methods = [OperatorNode._bin_op(left, binary_opnode, op, right, context)]\n+        elif helpers.is_supertype(left_type, right_type):\n+            methods = [\n+                OperatorNode._bin_op(\n+                    right, binary_opnode, op, left, reverse_context, reverse=True\n+                ),\n+                OperatorNode._bin_op(left, binary_opnode, op, right, context),\n+            ]\n+        else:\n+            methods = [\n+                OperatorNode._bin_op(left, binary_opnode, op, right, context),\n+                OperatorNode._bin_op(\n+                    right, binary_opnode, op, left, reverse_context, reverse=True\n+                ),\n+            ]\n+\n+        if (\n+            PY310_PLUS\n+            and op == \"|\"\n+            and (\n+                isinstance(left, (bases.UnionType, nodes.ClassDef))\n+                or isinstance(left, nodes.Const)\n+                and left.value is None\n+            )\n+            and (\n+                isinstance(right, (bases.UnionType, nodes.ClassDef))\n+                or isinstance(right, nodes.Const)\n+                and right.value is None\n+            )\n+        ):\n+            methods.extend([partial(OperatorNode._bin_op_or_union_type, left, right)])\n+        return methods\n+\n+    @staticmethod\n+    def _infer_binary_operation(\n+        left: InferenceResult,\n+        right: InferenceResult,\n+        binary_opnode: nodes.AugAssign | nodes.BinOp,\n+        context: InferenceContext,\n+        flow_factory: GetFlowFactory,\n+    ) -> Generator[InferenceResult | util.BadBinaryOperationMessage, None, None]:\n+        \"\"\"Infer a binary operation between a left operand and a right operand.\n+\n+        This is used by both normal binary operations and augmented binary\n+        operations, the only difference is the flow factory used.\n+        \"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        context, reverse_context = OperatorNode._get_binop_contexts(\n+            context, left, right\n+        )\n+        left_type = helpers.object_type(left)\n+        right_type = helpers.object_type(right)\n+        methods = flow_factory(\n+            left, left_type, binary_opnode, right, right_type, context, reverse_context\n+        )\n+        for method in methods:\n+            try:\n+                results = list(method())\n+            except AttributeError:\n+                continue\n+            except AttributeInferenceError:\n+                continue\n+            except InferenceError:\n+                yield util.Uninferable\n+                return\n+            else:\n+                if any(isinstance(result, util.UninferableBase) for result in results):\n+                    yield util.Uninferable\n+                    return\n+\n+                if all(map(OperatorNode._is_not_implemented, results)):\n+                    continue\n+                not_implemented = sum(\n+                    1 for result in results if OperatorNode._is_not_implemented(result)\n+                )\n+                if not_implemented and not_implemented != len(results):\n+                    # Can't infer yet what this is.\n+                    yield util.Uninferable\n+                    return\n+\n+                yield from results\n+                return\n+\n+        # The operation doesn't seem to be supported so let the caller know about it\n+        yield util.BadBinaryOperationMessage(left_type, binary_opnode.op, right_type)\n+\n+\n+class AttributeNode(NodeNG):\n+    expr: NodeNG\n+    \"\"\"The name that this node represents.\"\"\"\n+    attrname: str\n+\n+    @decorators.raise_if_nothing_inferred\n+    def _infer_attribute(\n+        self,\n+        context: InferenceContext | None = None,\n+        **kwargs: Any,\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo]:\n+        \"\"\"Infer an Attribute node by using getattr on the associated object.\"\"\"\n+        # pylint: disable=import-outside-toplevel\n+        from astroid.constraint import get_constraints\n+\n+        for owner in self.expr.infer(context):\n+            if isinstance(owner, util.UninferableBase):\n+                yield owner\n+                continue\n+\n+            context = copy_context(context)\n+            old_boundnode = context.boundnode\n+            try:\n+                context.boundnode = owner\n+                if isinstance(owner, (nodes.ClassDef, bases.Instance)):\n+                    frame = (\n+                        owner if isinstance(owner, nodes.ClassDef) else owner._proxied\n+                    )\n+                    context.constraints[self.attrname] = get_constraints(\n+                        self, frame=frame\n+                    )\n+                yield from owner.igetattr(self.attrname, context)\n+            except (\n+                AttributeInferenceError,\n+                InferenceError,\n+                AttributeError,\n+            ):\n+                pass\n+            finally:\n+                context.boundnode = old_boundnode\n+        return InferenceErrorInfo(node=self, context=context)\n+\n+\n+class AssignNode(NodeNG):\n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer_assign(\n+        self,\n+        context: InferenceContext | None = None,\n+        **kwargs: Any,\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Infer a AssignName/AssignAttr: need to inspect the RHS part of the\n+        assign node.\n+        \"\"\"\n+        if isinstance(self.parent, nodes.AugAssign):\n+            return self.parent.infer(context)\n+\n+        stmts = list(self.assigned_stmts(context=context))\n+        return bases._infer_stmts(stmts, context)\n+\n+    def assigned_stmts(\n+        self: nodes.AssignName | nodes.AssignAttr,\n+        node: AssignedStmtsPossibleNode = None,\n+        context: InferenceContext | None = None,\n+        assign_path: list[int] | None = None,\n+    ) -> Any:\n+        \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\"\"\"\n+        return self.parent.assigned_stmts(node=self, context=context)\n+\n+\n+class NameNode(LookupMixIn):\n+    name: str\n+\n+    @decorators.raise_if_nothing_inferred\n+    def _infer_name_node(\n+        self,\n+        context: InferenceContext | None = None,\n+        **kwargs: Any,\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Infer a Name: use name lookup rules.\"\"\"\n+        # pylint: disable=import-outside-toplevel\n+        from astroid.constraint import get_constraints\n+        from astroid.helpers import _higher_function_scope\n+\n+        frame, stmts = self.lookup(self.name)\n+        if not stmts:\n+            # Try to see if the name is enclosed in a nested function\n+            # and use the higher (first function) scope for searching.\n+            parent_function = _higher_function_scope(self.scope())\n+            if parent_function:\n+                _, stmts = parent_function.lookup(self.name)\n+\n+            if not stmts:\n+                raise NameInferenceError(\n+                    name=self.name, scope=self.scope(), context=context\n+                )\n+        context = copy_context(context)\n+        context.lookupname = self.name\n+        context.constraints[self.name] = get_constraints(self, frame)\n+\n+        return bases._infer_stmts(stmts, context, frame)\ndiff --git a/astroid/nodes/node_classes.py b/astroid/nodes/node_classes.py\nindex 349385e976..4f2bc949fe 100644\n--- a/astroid/nodes/node_classes.py\n+++ b/astroid/nodes/node_classes.py\n@@ -7,41 +7,46 @@\n from __future__ import annotations\n \n import abc\n+import ast\n import itertools\n+import operator\n import sys\n import typing\n import warnings\n from collections.abc import Generator, Iterable, Iterator, Mapping\n-from functools import cached_property, lru_cache\n+from functools import cached_property\n from typing import (\n     TYPE_CHECKING,\n     Any,\n     Callable,\n-    ClassVar,\n     Literal,\n     Optional,\n     Union,\n )\n \n-from astroid import decorators, util\n+from astroid import decorators, protocols, util\n from astroid.bases import Instance, _infer_stmts\n from astroid.const import _EMPTY_OBJECT_MARKER, Context\n-from astroid.context import InferenceContext\n+from astroid.context import CallContext, InferenceContext, copy_context\n from astroid.exceptions import (\n+    AstroidBuildingError,\n+    AstroidError,\n     AstroidIndexError,\n     AstroidTypeError,\n     AstroidValueError,\n+    AttributeInferenceError,\n     InferenceError,\n     NoDefault,\n     ParentMissingError,\n+    _NonDeducibleTypeHierarchy,\n )\n+from astroid.interpreter import dunder_lookup\n from astroid.manager import AstroidManager\n from astroid.nodes import _base_nodes\n from astroid.nodes.const import OP_PRECEDENCE\n from astroid.nodes.node_ng import NodeNG\n from astroid.typing import (\n     ConstFactoryResult,\n-    InferBinaryOp,\n     InferenceErrorInfo,\n     InferenceResult,\n     SuccessfulInferenceResult,\n@@ -52,7 +57,6 @@\n else:\n     from typing_extensions import Self\n \n-\n if TYPE_CHECKING:\n     from astroid import nodes\n     from astroid.nodes import LocalsDictNodeNG\n@@ -337,46 +341,67 @@ def pytype(self) -> str:\n     def get_children(self):\n         yield from self.elts\n \n+    @decorators.raise_if_nothing_inferred\n+    def _infer(\n+        self,\n+        context: InferenceContext | None = None,\n+        **kwargs: Any,\n+    ) -> Iterator[Self]:\n+        has_starred_named_expr = any(\n+            isinstance(e, (Starred, NamedExpr)) for e in self.elts\n+        )\n+        if has_starred_named_expr:\n+            values = self._infer_sequence_helper(context)\n+            new_seq = type(self)(\n+                lineno=self.lineno,\n+                col_offset=self.col_offset,\n+                parent=self.parent,\n+                end_lineno=self.end_lineno,\n+                end_col_offset=self.end_col_offset,\n+            )\n+            new_seq.postinit(values)\n \n-# TODO: Move into _base_nodes. Blocked by import of _infer_stmts from bases.\n-class LookupMixIn(NodeNG):\n-    \"\"\"Mixin to look up a name in the right scope.\"\"\"\n-\n-    @lru_cache  # noqa\n-    def lookup(self, name: str) -> tuple[LocalsDictNodeNG, list[NodeNG]]:\n-        \"\"\"Lookup where the given variable is assigned.\n-\n-        The lookup starts from self's scope. If self is not a frame itself\n-        and the name is found in the inner frame locals, statements will be\n-        filtered to remove ignorable statements according to self's location.\n-\n-        :param name: The name of the variable to find assignments for.\n-\n-        :returns: The scope node and the list of assignments associated to the\n-            given name according to the scope where it has been found (locals,\n-            globals or builtin).\n-        \"\"\"\n-        return self.scope().scope_lookup(self, name)\n-\n-    def ilookup(self, name):\n-        \"\"\"Lookup the inferred values of the given variable.\n-\n-        :param name: The variable name to find values for.\n-        :type name: str\n-\n-        :returns: The inferred values of the statements returned from\n-            :meth:`lookup`.\n-        :rtype: iterable\n-        \"\"\"\n-        frame, stmts = self.lookup(name)\n-        context = InferenceContext()\n-        return _infer_stmts(stmts, context, frame)\n+            yield new_seq\n+        else:\n+            yield self\n+\n+    def _infer_sequence_helper(\n+        self, context: InferenceContext | None = None\n+    ) -> list[SuccessfulInferenceResult]:\n+        \"\"\"Infer all values based on BaseContainer.elts.\"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        values = []\n+\n+        for elt in self.elts:\n+            if isinstance(elt, Starred):\n+                starred = helpers.safe_infer(elt.value, context)\n+                if not starred:\n+                    raise InferenceError(node=self, context=context)\n+                if not hasattr(starred, \"elts\"):\n+                    raise InferenceError(node=self, context=context)\n+                # TODO: fresh context?\n+                values.extend(starred._infer_sequence_helper(context))\n+            elif isinstance(elt, NamedExpr):\n+                value = helpers.safe_infer(elt.value, context)\n+                if not value:\n+                    raise InferenceError(node=self, context=context)\n+                values.append(value)\n+            else:\n+                values.append(elt)\n+        return values\n \n \n # Name classes\n \n \n-class AssignName(_base_nodes.NoChildrenNode, LookupMixIn, _base_nodes.ParentAssignNode):\n+class AssignName(\n+    _base_nodes.NameNode,\n+    _base_nodes.AssignNode,\n+    _base_nodes.NoChildrenNode,\n+    _base_nodes.LookupMixIn,\n+    _base_nodes.ParentAssignNode,\n+):\n     \"\"\"Variation of :class:`ast.Assign` representing assignment to a name.\n \n     An :class:`AssignName` is the name of something that is assigned to.\n@@ -394,8 +419,6 @@ class AssignName(_base_nodes.NoChildrenNode, LookupMixIn, _base_nodes.ParentAssi\n \n     _other_fields = (\"name\",)\n \n-    infer_lhs: ClassVar[InferLHS[AssignName]]\n-\n     def __init__(\n         self,\n         name: str,\n@@ -417,13 +440,26 @@ def __init__(\n             parent=parent,\n         )\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[AssignName]]\n+    assigned_stmts = protocols.assend_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        return self._infer_assign(context, **kwargs)\n+\n+    @decorators.raise_if_nothing_inferred\n+    def infer_lhs(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        return self._infer_name_node(context, **kwargs)\n+\n \n-class DelName(_base_nodes.NoChildrenNode, LookupMixIn, _base_nodes.ParentAssignNode):\n+class DelName(\n+    _base_nodes.NoChildrenNode, _base_nodes.LookupMixIn, _base_nodes.ParentAssignNode\n+):\n     \"\"\"Variation of :class:`ast.Delete` representing deletion of a name.\n \n     A :class:`DelName` is the name of something that is deleted.\n@@ -460,7 +496,7 @@ def __init__(\n         )\n \n \n-class Name(_base_nodes.NoChildrenNode, LookupMixIn):\n+class Name(_base_nodes.NameNode, _base_nodes.NoChildrenNode):\n     \"\"\"Class representing an :class:`ast.Name` node.\n \n     A :class:`Name` node is something that is named, but not covered by\n@@ -505,6 +541,12 @@ def _get_name_nodes(self):\n         for child_node in self.get_children():\n             yield from child_node._get_name_nodes()\n \n+    @decorators.path_wrapper\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        return self._infer_name_node(context, **kwargs)\n+\n \n DEPRECATED_ARGUMENT_DEFAULT = object()\n \n@@ -663,7 +705,7 @@ def postinit(\n             type_comment_posonlyargs = []\n         self.type_comment_posonlyargs = type_comment_posonlyargs\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[Arguments]]\n+    assigned_stmts = protocols.arguments_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -894,6 +936,17 @@ def get_children(self):\n             if elt is not None:\n                 yield elt\n \n+    @decorators.raise_if_nothing_inferred\n+    def _infer(\n+        self: nodes.Arguments, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        # pylint: disable-next=import-outside-toplevel\n+        from astroid.protocols import _arguments_infer_argname\n+\n+        if context is None or context.lookupname is None:\n+            raise InferenceError(node=self, context=context)\n+        return _arguments_infer_argname(self, context.lookupname, context)\n+\n \n def _find_arg(argname, args):\n     for i, arg in enumerate(args):\n@@ -934,7 +987,9 @@ def _format_args(\n     return \", \".join(values)\n \n \n-class AssignAttr(_base_nodes.ParentAssignNode):\n+class AssignAttr(\n+    _base_nodes.AttributeNode, _base_nodes.AssignNode, _base_nodes.ParentAssignNode\n+):\n     \"\"\"Variation of :class:`ast.Assign` representing assignment to an attribute.\n \n     >>> import astroid\n@@ -950,11 +1005,6 @@ class AssignAttr(_base_nodes.ParentAssignNode):\n     _astroid_fields = (\"expr\",)\n     _other_fields = (\"attrname\",)\n \n-    infer_lhs: ClassVar[InferLHS[AssignAttr]]\n-\n-    expr: NodeNG\n-    \"\"\"What has the attribute that is being assigned to.\"\"\"\n-\n     def __init__(\n         self,\n         attrname: str,\n@@ -979,7 +1029,7 @@ def __init__(\n     def postinit(self, expr: NodeNG) -> None:\n         self.expr = expr\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[AssignAttr]]\n+    assigned_stmts = protocols.assend_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -987,6 +1037,16 @@ def postinit(self, expr: NodeNG) -> None:\n     def get_children(self):\n         yield self.expr\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        return self._infer_assign(context, **kwargs)\n+\n+    def infer_lhs(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        return self._infer_attribute(context, **kwargs)\n+\n \n class Assert(_base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.Assert` node.\n@@ -1052,7 +1112,7 @@ def postinit(\n         self.value = value\n         self.type_annotation = type_annotation\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[Assign]]\n+    assigned_stmts = protocols.assign_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -1108,7 +1168,7 @@ def postinit(\n         self.value = value\n         self.simple = simple\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[AnnAssign]]\n+    assigned_stmts = protocols.assign_annassigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -1121,7 +1181,9 @@ def get_children(self):\n             yield self.value\n \n \n-class AugAssign(_base_nodes.AssignTypeNode, _base_nodes.Statement):\n+class AugAssign(\n+    _base_nodes.AssignTypeNode, _base_nodes.OperatorNode, _base_nodes.Statement\n+):\n     \"\"\"Class representing an :class:`ast.AugAssign` node.\n \n     An :class:`AugAssign` is an assignment paired with an operator.\n@@ -1169,16 +1231,11 @@ def postinit(self, target: Name | Attribute | Subscript, value: NodeNG) -> None:\n         self.target = target\n         self.value = value\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[AugAssign]]\n+    assigned_stmts = protocols.assign_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n \n-    # This is set by inference.py\n-    _infer_augassign: ClassVar[\n-        InferBinaryOperation[AugAssign, util.BadBinaryOperationMessage]\n-    ]\n-\n     def type_errors(self, context: InferenceContext | None = None):\n         \"\"\"Get a list of type errors which can occur during inference.\n \n@@ -1207,8 +1264,45 @@ def _get_yield_nodes_skip_lambdas(self):\n         yield from self.value._get_yield_nodes_skip_lambdas()\n         yield from super()._get_yield_nodes_skip_lambdas()\n \n+    def _infer_augassign(\n+        self, context: InferenceContext | None = None\n+    ) -> Generator[InferenceResult | util.BadBinaryOperationMessage, None, None]:\n+        \"\"\"Inference logic for augmented binary operations.\"\"\"\n+        context = context or InferenceContext()\n+\n+        rhs_context = context.clone()\n+\n+        lhs_iter = self.target.infer_lhs(context=context)\n+        rhs_iter = self.value.infer(context=rhs_context)\n+\n+        for lhs, rhs in itertools.product(lhs_iter, rhs_iter):\n+            if any(isinstance(value, util.UninferableBase) for value in (rhs, lhs)):\n+                # Don't know how to process this.\n+                yield util.Uninferable\n+                return\n+\n+            try:\n+                yield from self._infer_binary_operation(\n+                    left=lhs,\n+                    right=rhs,\n+                    binary_opnode=self,\n+                    context=context,\n+                    flow_factory=self._get_aug_flow,\n+                )\n+            except _NonDeducibleTypeHierarchy:\n+                yield util.Uninferable\n \n-class BinOp(NodeNG):\n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self: nodes.AugAssign, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        return self._filter_operation_errors(\n+            self._infer_augassign, context, util.BadBinaryOperationMessage\n+        )\n+\n+\n+class BinOp(_base_nodes.OperatorNode):\n     \"\"\"Class representing an :class:`ast.BinOp` node.\n \n     A :class:`BinOp` node is an application of a binary operator.\n@@ -1253,9 +1347,6 @@ def postinit(self, left: NodeNG, right: NodeNG) -> None:\n         self.left = left\n         self.right = right\n \n-    # This is set by inference.py\n-    _infer_binop: ClassVar[InferBinaryOperation[BinOp, util.BadBinaryOperationMessage]]\n-\n     def type_errors(self, context: InferenceContext | None = None):\n         \"\"\"Get a list of type errors which can occur during inference.\n \n@@ -1286,6 +1377,43 @@ def op_left_associative(self) -> bool:\n         # 2**3**4 == 2**(3**4)\n         return self.op != \"**\"\n \n+    def _infer_binop(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Binary operation inference logic.\"\"\"\n+        left = self.left\n+        right = self.right\n+\n+        # we use two separate contexts for evaluating lhs and rhs because\n+        # 1. evaluating lhs may leave some undesired entries in context.path\n+        #    which may not let us infer right value of rhs\n+        context = context or InferenceContext()\n+        lhs_context = copy_context(context)\n+        rhs_context = copy_context(context)\n+        lhs_iter = left.infer(context=lhs_context)\n+        rhs_iter = right.infer(context=rhs_context)\n+        for lhs, rhs in itertools.product(lhs_iter, rhs_iter):\n+            if any(isinstance(value, util.UninferableBase) for value in (rhs, lhs)):\n+                # Don't know how to process this.\n+                yield util.Uninferable\n+                return\n+\n+            try:\n+                yield from self._infer_binary_operation(\n+                    lhs, rhs, self, context, self._get_binop_flow\n+                )\n+            except _NonDeducibleTypeHierarchy:\n+                yield util.Uninferable\n+\n+    @decorators.yes_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self: nodes.BinOp, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        return self._filter_operation_errors(\n+            self._infer_binop, context, util.BadBinaryOperationMessage\n+        )\n+\n \n class BoolOp(NodeNG):\n     \"\"\"Class representing an :class:`ast.BoolOp` node.\n@@ -1355,6 +1483,60 @@ def get_children(self):\n     def op_precedence(self):\n         return OP_PRECEDENCE[self.op]\n \n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self: nodes.BoolOp, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        \"\"\"Infer a boolean operation (and / or / not).\n+\n+        The function will calculate the boolean operation\n+        for all pairs generated through inference for each component\n+        node.\n+        \"\"\"\n+        values = self.values\n+        if self.op == \"or\":\n+            predicate = operator.truth\n+        else:\n+            predicate = operator.not_\n+\n+        try:\n+            inferred_values = [value.infer(context=context) for value in values]\n+        except InferenceError:\n+            yield util.Uninferable\n+            return None\n+\n+        for pair in itertools.product(*inferred_values):\n+            if any(isinstance(item, util.UninferableBase) for item in pair):\n+                # Can't infer the final result, just yield Uninferable.\n+                yield util.Uninferable\n+                continue\n+\n+            bool_values = [item.bool_value() for item in pair]\n+            if any(isinstance(item, util.UninferableBase) for item in bool_values):\n+                # Can't infer the final result, just yield Uninferable.\n+                yield util.Uninferable\n+                continue\n+\n+            # Since the boolean operations are short circuited operations,\n+            # this code yields the first value for which the predicate is True\n+            # and if no value respected the predicate, then the last value will\n+            # be returned (or Uninferable if there was no last value).\n+            # This is conforming to the semantics of `and` and `or`:\n+            #   1 and 0 -> 1\n+            #   0 and 1 -> 0\n+            #   1 or 0 -> 1\n+            #   0 or 1 -> 1\n+            value = util.Uninferable\n+            for value, bool_value in zip(pair, bool_values):\n+                if predicate(bool_value):\n+                    yield value\n+                    break\n+            else:\n+                yield value\n+\n+        return InferenceErrorInfo(node=self, context=context)\n+\n \n class Break(_base_nodes.NoChildrenNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.Break` node.\n@@ -1412,6 +1594,64 @@ def get_children(self):\n \n         yield from self.keywords\n \n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo]:\n+        \"\"\"Infer a Call node by trying to guess what the function returns.\"\"\"\n+        callcontext = copy_context(context)\n+        callcontext.boundnode = None\n+        if context is not None:\n+            callcontext.extra_context = self._populate_context_lookup(context.clone())\n+\n+        for callee in self.func.infer(context):\n+            if isinstance(callee, util.UninferableBase):\n+                yield callee\n+                continue\n+            try:\n+                if hasattr(callee, \"infer_call_result\"):\n+                    callcontext.callcontext = CallContext(\n+                        args=self.args, keywords=self.keywords, callee=callee\n+                    )\n+                    yield from callee.infer_call_result(\n+                        caller=self, context=callcontext\n+                    )\n+            except InferenceError:\n+                continue\n+        return InferenceErrorInfo(node=self, context=context)\n+\n+    def _populate_context_lookup(self, context: InferenceContext | None):\n+        \"\"\"Allows context to be saved for later for inference inside a function.\"\"\"\n+        context_lookup: dict[InferenceResult, InferenceContext] = {}\n+        if context is None:\n+            return context_lookup\n+        for arg in self.args:\n+            if isinstance(arg, Starred):\n+                context_lookup[arg.value] = context\n+            else:\n+                context_lookup[arg] = context\n+        keywords = self.keywords if self.keywords is not None else []\n+        for keyword in keywords:\n+            context_lookup[keyword.value] = context\n+        return context_lookup\n+\n+\n+COMPARE_OPS: dict[str, Callable[[Any, Any], bool]] = {\n+    \"==\": operator.eq,\n+    \"!=\": operator.ne,\n+    \"<\": operator.lt,\n+    \"<=\": operator.le,\n+    \">\": operator.gt,\n+    \">=\": operator.ge,\n+    \"in\": lambda a, b: a in b,\n+    \"not in\": lambda a, b: a not in b,\n+}\n+UNINFERABLE_OPS = {\n+    \"is\",\n+    \"is not\",\n+}\n+\n \n class Compare(NodeNG):\n     \"\"\"Class representing an :class:`ast.Compare` node.\n@@ -1461,6 +1701,88 @@ def last_child(self):\n         return self.ops[-1][1]\n         # return self.left\n \n+    # TODO: move to util?\n+    @staticmethod\n+    def _to_literal(node: SuccessfulInferenceResult) -> Any:\n+        # Can raise SyntaxError or ValueError from ast.literal_eval\n+        # Can raise AttributeError from node.as_string() as not all nodes have a visitor\n+        # Is this the stupidest idea or the simplest idea?\n+        return ast.literal_eval(node.as_string())\n+\n+    def _do_compare(\n+        self,\n+        left_iter: Iterable[InferenceResult],\n+        op: str,\n+        right_iter: Iterable[InferenceResult],\n+    ) -> bool | util.UninferableBase:\n+        \"\"\"\n+        If all possible combinations are either True or False, return that:\n+        >>> _do_compare([1, 2], '<=', [3, 4])\n+        True\n+        >>> _do_compare([1, 2], '==', [3, 4])\n+        False\n+\n+        If any item is uninferable, or if some combinations are True and some\n+        are False, return Uninferable:\n+        >>> _do_compare([1, 3], '<=', [2, 4])\n+        util.Uninferable\n+        \"\"\"\n+        retval: bool | None = None\n+        if op in UNINFERABLE_OPS:\n+            return util.Uninferable\n+        op_func = COMPARE_OPS[op]\n+\n+        for left, right in itertools.product(left_iter, right_iter):\n+            if isinstance(left, util.UninferableBase) or isinstance(\n+                right, util.UninferableBase\n+            ):\n+                return util.Uninferable\n+\n+            try:\n+                left, right = self._to_literal(left), self._to_literal(right)\n+            except (SyntaxError, ValueError, AttributeError):\n+                return util.Uninferable\n+\n+            try:\n+                expr = op_func(left, right)\n+            except TypeError as exc:\n+                raise AstroidTypeError from exc\n+\n+            if retval is None:\n+                retval = expr\n+            elif retval != expr:\n+                return util.Uninferable\n+                # (or both, but \"True | False\" is basically the same)\n+\n+        assert retval is not None\n+        return retval  # it was all the same value\n+\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[nodes.Const | util.UninferableBase, None, None]:\n+        \"\"\"Chained comparison inference logic.\"\"\"\n+        retval: bool | util.UninferableBase = True\n+\n+        ops = self.ops\n+        left_node = self.left\n+        lhs = list(left_node.infer(context=context))\n+        # should we break early if first element is uninferable?\n+        for op, right_node in ops:\n+            # eagerly evaluate rhs so that values can be re-used as lhs\n+            rhs = list(right_node.infer(context=context))\n+            try:\n+                retval = self._do_compare(lhs, op, rhs)\n+            except AstroidTypeError:\n+                retval = util.Uninferable\n+                break\n+            if retval is not True:\n+                break  # short-circuit\n+            lhs = rhs  # continue\n+        if retval is util.Uninferable:\n+            yield retval  # type: ignore[misc]\n+        else:\n+            yield Const(retval)\n+\n \n class Comprehension(NodeNG):\n     \"\"\"Class representing an :class:`ast.comprehension` node.\n@@ -1506,7 +1828,7 @@ def postinit(\n         self.ifs = ifs\n         self.is_async = is_async\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[Comprehension]]\n+    assigned_stmts = protocols.for_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -1603,8 +1925,8 @@ def __init__(\n \n         Instance.__init__(self, None)\n \n-    infer_unary_op: ClassVar[InferUnaryOp[Const]]\n-    infer_binary_op: ClassVar[InferBinaryOp[Const]]\n+    infer_unary_op = protocols.const_infer_unary_op\n+    infer_binary_op = protocols.const_infer_binary_op\n \n     def __getattr__(self, name):\n         # This is needed because of Proxy's __getattr__ method.\n@@ -1692,6 +2014,11 @@ def bool_value(self, context: InferenceContext | None = None):\n         \"\"\"\n         return bool(self.value)\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[Const]:\n+        yield self\n+\n \n class Continue(_base_nodes.NoChildrenNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.Continue` node.\n@@ -1871,7 +2198,7 @@ def postinit(self, items: list[tuple[InferenceResult, InferenceResult]]) -> None\n         \"\"\"\n         self.items = items\n \n-    infer_unary_op: ClassVar[InferUnaryOp[Dict]]\n+    infer_unary_op = protocols.dict_infer_unary_op\n \n     def pytype(self) -> Literal[\"builtins.dict\"]:\n         \"\"\"Get the name of the type that this node represents.\n@@ -1923,13 +2250,12 @@ def getitem(\n         :raises AstroidIndexError: If the given index does not exist in the\n             dictionary.\n         \"\"\"\n-        # pylint: disable-next=import-outside-toplevel; circular import\n-        from astroid.helpers import safe_infer\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n \n         for key, value in self.items:\n             # TODO(cpopa): no support for overriding yet, {1:2, **{1: 3}}.\n             if isinstance(key, DictUnpack):\n-                inferred_value = safe_infer(value, context)\n+                inferred_value = helpers.safe_infer(value, context)\n                 if not isinstance(inferred_value, Dict):\n                     continue\n \n@@ -1955,6 +2281,74 @@ def bool_value(self, context: InferenceContext | None = None):\n         \"\"\"\n         return bool(self.items)\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[nodes.Dict]:\n+        if not any(isinstance(k, DictUnpack) for k, _ in self.items):\n+            yield self\n+        else:\n+            items = self._infer_map(context)\n+            new_seq = type(self)(\n+                lineno=self.lineno,\n+                col_offset=self.col_offset,\n+                parent=self.parent,\n+                end_lineno=self.end_lineno,\n+                end_col_offset=self.end_col_offset,\n+            )\n+            new_seq.postinit(list(items.items()))\n+            yield new_seq\n+\n+    @staticmethod\n+    def _update_with_replacement(\n+        lhs_dict: dict[SuccessfulInferenceResult, SuccessfulInferenceResult],\n+        rhs_dict: dict[SuccessfulInferenceResult, SuccessfulInferenceResult],\n+    ) -> dict[SuccessfulInferenceResult, SuccessfulInferenceResult]:\n+        \"\"\"Delete nodes that equate to duplicate keys.\n+\n+        Since an astroid node doesn't 'equal' another node with the same value,\n+        this function uses the as_string method to make sure duplicate keys\n+        don't get through\n+\n+        Note that both the key and the value are astroid nodes\n+\n+        Fixes issue with DictUnpack causing duplicate keys\n+        in inferred Dict items\n+\n+        :param lhs_dict: Dictionary to 'merge' nodes into\n+        :param rhs_dict: Dictionary with nodes to pull from\n+        :return : merged dictionary of nodes\n+        \"\"\"\n+        combined_dict = itertools.chain(lhs_dict.items(), rhs_dict.items())\n+        # Overwrite keys which have the same string values\n+        string_map = {key.as_string(): (key, value) for key, value in combined_dict}\n+        # Return to dictionary\n+        return dict(string_map.values())\n+\n+    def _infer_map(\n+        self, context: InferenceContext | None\n+    ) -> dict[SuccessfulInferenceResult, SuccessfulInferenceResult]:\n+        \"\"\"Infer all values based on Dict.items.\"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        values: dict[SuccessfulInferenceResult, SuccessfulInferenceResult] = {}\n+        for name, value in self.items:\n+            if isinstance(name, DictUnpack):\n+                double_starred = helpers.safe_infer(value, context)\n+                if not double_starred:\n+                    raise InferenceError\n+                if not isinstance(double_starred, Dict):\n+                    raise InferenceError(node=self, context=context)\n+                unpack_items = double_starred._infer_map(context)\n+                values = self._update_with_replacement(values, unpack_items)\n+            else:\n+                key = helpers.safe_infer(name, context=context)\n+                safe_value = helpers.safe_infer(value, context=context)\n+                if any(not elem for elem in (key, safe_value)):\n+                    raise InferenceError(node=self, context=context)\n+                # safe_value is SuccessfulInferenceResult as bool(Uninferable) == False\n+                values = self._update_with_replacement(values, {key: safe_value})\n+        return values\n+\n \n class Expr(_base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.Expr` node.\n@@ -2011,6 +2405,21 @@ def __init__(\n     def has_underlying_object(self) -> bool:\n         return self.object is not None and self.object is not _EMPTY_OBJECT_MARKER\n \n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        if not self.has_underlying_object():\n+            yield util.Uninferable\n+        else:\n+            try:\n+                yield from AstroidManager().infer_ast_from_something(\n+                    self.object, context=context\n+                )\n+            except AstroidError:\n+                yield util.Uninferable\n+\n \n class ExceptHandler(\n     _base_nodes.MultiLineBlockNode, _base_nodes.AssignTypeNode, _base_nodes.Statement\n@@ -2044,7 +2453,7 @@ class ExceptHandler(\n     body: list[NodeNG]\n     \"\"\"The contents of the block.\"\"\"\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[ExceptHandler]]\n+    assigned_stmts = protocols.excepthandler_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -2142,7 +2551,7 @@ def postinit(\n         self.orelse = orelse\n         self.type_annotation = type_annotation\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[For]]\n+    assigned_stmts = protocols.for_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -2283,16 +2692,47 @@ def __init__(\n             parent=parent,\n         )\n \n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self,\n+        context: InferenceContext | None = None,\n+        asname: bool = True,\n+        **kwargs: Any,\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Infer a ImportFrom node: return the imported module/object.\"\"\"\n+        context = context or InferenceContext()\n+        name = context.lookupname\n+        if name is None:\n+            raise InferenceError(node=self, context=context)\n+        if asname:\n+            try:\n+                name = self.real_name(name)\n+            except AttributeInferenceError as exc:\n+                # See https://github.com/pylint-dev/pylint/issues/4692\n+                raise InferenceError(node=self, context=context) from exc\n+        try:\n+            module = self.do_import_module()\n+        except AstroidBuildingError as exc:\n+            raise InferenceError(node=self, context=context) from exc\n+\n+        try:\n+            context = copy_context(context)\n+            context.lookupname = name\n+            stmts = module.getattr(name, ignore_locals=module is self.root())\n+            return _infer_stmts(stmts, context)\n+        except AttributeInferenceError as error:\n+            raise InferenceError(\n+                str(error), target=self, attribute=name, context=context\n+            ) from error\n+\n \n-class Attribute(NodeNG):\n+class Attribute(_base_nodes.AttributeNode):\n     \"\"\"Class representing an :class:`ast.Attribute` node.\"\"\"\n \n     _astroid_fields = (\"expr\",)\n     _other_fields = (\"attrname\",)\n \n-    expr: NodeNG\n-    \"\"\"The name that this node represents.\"\"\"\n-\n     def __init__(\n         self,\n         attrname: str,\n@@ -2320,6 +2760,12 @@ def postinit(self, expr: NodeNG) -> None:\n     def get_children(self):\n         yield self.expr\n \n+    @decorators.path_wrapper\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        return self._infer_attribute(context, **kwargs)\n+\n \n class Global(_base_nodes.NoChildrenNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.Global` node.\n@@ -2371,6 +2817,21 @@ def __init__(\n     def _infer_name(self, frame, name):\n         return name\n \n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        if context is None or context.lookupname is None:\n+            raise InferenceError(node=self, context=context)\n+        try:\n+            # pylint: disable-next=no-member\n+            return _infer_stmts(self.root().getattr(context.lookupname), context)\n+        except AttributeInferenceError as error:\n+            raise InferenceError(\n+                str(error), target=self, attribute=context.lookupname, context=context\n+            ) from error\n+\n \n class If(_base_nodes.MultiLineWithElseBlockNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.If` node.\n@@ -2469,6 +2930,40 @@ def op_left_associative(self) -> Literal[False]:\n         # `1 if True else (2 if False else 3)`\n         return False\n \n+    @decorators.raise_if_nothing_inferred\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, None]:\n+        \"\"\"Support IfExp inference.\n+\n+        If we can't infer the truthiness of the condition, we default\n+        to inferring both branches. Otherwise, we infer either branch\n+        depending on the condition.\n+        \"\"\"\n+        both_branches = False\n+        # We use two separate contexts for evaluating lhs and rhs because\n+        # evaluating lhs may leave some undesired entries in context.path\n+        # which may not let us infer right value of rhs.\n+\n+        context = context or InferenceContext()\n+        lhs_context = copy_context(context)\n+        rhs_context = copy_context(context)\n+        try:\n+            test = next(self.test.infer(context=context.clone()))\n+        except (InferenceError, StopIteration):\n+            both_branches = True\n+        else:\n+            if not isinstance(test, util.UninferableBase):\n+                if test.bool_value():\n+                    yield from self.body.infer(context=lhs_context)\n+                else:\n+                    yield from self.orelse.infer(context=rhs_context)\n+            else:\n+                both_branches = True\n+        if both_branches:\n+            yield from self.body.infer(context=lhs_context)\n+            yield from self.orelse.infer(context=rhs_context)\n+\n \n class Import(_base_nodes.ImportNode):\n     \"\"\"Class representing an :class:`ast.Import` node.\n@@ -2521,6 +3016,28 @@ def __init__(\n             parent=parent,\n         )\n \n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self,\n+        context: InferenceContext | None = None,\n+        asname: bool = True,\n+        **kwargs: Any,\n+    ) -> Generator[nodes.Module, None, None]:\n+        \"\"\"Infer an Import node: return the imported module/object.\"\"\"\n+        context = context or InferenceContext()\n+        name = context.lookupname\n+        if name is None:\n+            raise InferenceError(node=self, context=context)\n+\n+        try:\n+            if asname:\n+                yield self.do_import_module(self.real_name(name))\n+            else:\n+                yield self.do_import_module(name)\n+        except AstroidBuildingError as exc:\n+            raise InferenceError(node=self, context=context) from exc\n+\n \n class Keyword(NodeNG):\n     \"\"\"Class representing an :class:`ast.keyword` node.\n@@ -2614,13 +3131,13 @@ def __init__(\n             parent=parent,\n         )\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[List]]\n+    assigned_stmts = protocols.sequence_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n \n-    infer_unary_op: ClassVar[InferUnaryOp[List]]\n-    infer_binary_op: ClassVar[InferBinaryOp[List]]\n+    infer_unary_op = protocols.list_infer_unary_op\n+    infer_binary_op = protocols.tl_infer_binary_op\n \n     def pytype(self) -> Literal[\"builtins.list\"]:\n         \"\"\"Get the name of the type that this node represents.\n@@ -2727,6 +3244,11 @@ def __init__(\n     def postinit(self, *, name: AssignName) -> None:\n         self.name = name\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[ParamSpec]:\n+        yield self\n+\n \n class Pass(_base_nodes.NoChildrenNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.Pass` node.\n@@ -2819,7 +3341,7 @@ class Set(BaseContainer):\n     <Set.set l.1 at 0x7f23b2e71d68>\n     \"\"\"\n \n-    infer_unary_op: ClassVar[InferUnaryOp[Set]]\n+    infer_unary_op = protocols.set_infer_unary_op\n \n     def pytype(self) -> Literal[\"builtins.set\"]:\n         \"\"\"Get the name of the type that this node represents.\n@@ -2912,6 +3434,11 @@ def get_children(self):\n         if self.step is not None:\n             yield self.step\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[Slice]:\n+        yield self\n+\n \n class Starred(_base_nodes.ParentAssignNode):\n     \"\"\"Class representing an :class:`ast.Starred` node.\n@@ -2952,7 +3479,7 @@ def __init__(\n     def postinit(self, value: NodeNG) -> None:\n         self.value = value\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[Starred]]\n+    assigned_stmts = protocols.starred_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -2970,11 +3497,10 @@ class Subscript(NodeNG):\n     <Subscript l.1 at 0x7f23b2e71f60>\n     \"\"\"\n \n+    _SUBSCRIPT_SENTINEL = object()\n     _astroid_fields = (\"value\", \"slice\")\n     _other_fields = (\"ctx\",)\n \n-    infer_lhs: ClassVar[InferLHS[Subscript]]\n-\n     value: NodeNG\n     \"\"\"What is being indexed.\"\"\"\n \n@@ -3011,6 +3537,74 @@ def get_children(self):\n         yield self.value\n         yield self.slice\n \n+    def _infer_subscript(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo | None]:\n+        \"\"\"Inference for subscripts.\n+\n+        We're understanding if the index is a Const\n+        or a slice, passing the result of inference\n+        to the value's `getitem` method, which should\n+        handle each supported index type accordingly.\n+        \"\"\"\n+        from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n+        found_one = False\n+        for value in self.value.infer(context):\n+            if isinstance(value, util.UninferableBase):\n+                yield util.Uninferable\n+                return None\n+            for index in self.slice.infer(context):\n+                if isinstance(index, util.UninferableBase):\n+                    yield util.Uninferable\n+                    return None\n+\n+                # Try to deduce the index value.\n+                index_value = self._SUBSCRIPT_SENTINEL\n+                if value.__class__ == Instance:\n+                    index_value = index\n+                elif index.__class__ == Instance:\n+                    instance_as_index = helpers.class_instance_as_index(index)\n+                    if instance_as_index:\n+                        index_value = instance_as_index\n+                else:\n+                    index_value = index\n+\n+                if index_value is self._SUBSCRIPT_SENTINEL:\n+                    raise InferenceError(node=self, context=context)\n+\n+                try:\n+                    assigned = value.getitem(index_value, context)\n+                except (\n+                    AstroidTypeError,\n+                    AstroidIndexError,\n+                    AstroidValueError,\n+                    AttributeInferenceError,\n+                    AttributeError,\n+                ) as exc:\n+                    raise InferenceError(node=self, context=context) from exc\n+\n+                # Prevent inferring if the inferred subscript\n+                # is the same as the original subscripted object.\n+                if self is assigned or isinstance(assigned, util.UninferableBase):\n+                    yield util.Uninferable\n+                    return None\n+                yield from assigned.infer(context)\n+                found_one = True\n+\n+        if found_one:\n+            return InferenceErrorInfo(node=self, context=context)\n+        return None\n+\n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(self, context: InferenceContext | None = None, **kwargs: Any):\n+        return self._infer_subscript(context, **kwargs)\n+\n+    @decorators.raise_if_nothing_inferred\n+    def infer_lhs(self, context: InferenceContext | None = None, **kwargs: Any):\n+        return self._infer_subscript(context, **kwargs)\n+\n \n class TryExcept(_base_nodes.MultiLineWithElseBlockNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.TryExcept` node.\n@@ -3318,13 +3912,13 @@ def __init__(\n             parent=parent,\n         )\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[Tuple]]\n+    assigned_stmts = protocols.sequence_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n \n-    infer_unary_op: ClassVar[InferUnaryOp[Tuple]]\n-    infer_binary_op: ClassVar[InferBinaryOp[Tuple]]\n+    infer_unary_op = protocols.tuple_infer_unary_op\n+    infer_binary_op = protocols.tl_infer_binary_op\n \n     def pytype(self) -> Literal[\"builtins.tuple\"]:\n         \"\"\"Get the name of the type that this node represents.\n@@ -3385,6 +3979,11 @@ def postinit(\n         self.type_params = type_params\n         self.value = value\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[TypeAlias]:\n+        yield self\n+\n \n class TypeVar(_base_nodes.AssignTypeNode):\n     \"\"\"Class representing a :class:`ast.TypeVar` node.\n@@ -3421,6 +4020,11 @@ def postinit(self, *, name: AssignName, bound: NodeNG | None) -> None:\n         self.name = name\n         self.bound = bound\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[TypeVar]:\n+        yield self\n+\n \n class TypeVarTuple(_base_nodes.AssignTypeNode):\n     \"\"\"Class representing a :class:`ast.TypeVarTuple` node.\n@@ -3455,8 +4059,21 @@ def __init__(\n     def postinit(self, *, name: AssignName) -> None:\n         self.name = name\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[TypeVarTuple]:\n+        yield self\n+\n \n-class UnaryOp(NodeNG):\n+UNARY_OP_METHOD = {\n+    \"+\": \"__pos__\",\n+    \"-\": \"__neg__\",\n+    \"~\": \"__invert__\",\n+    \"not\": None,  # XXX not '__nonzero__'\n+}\n+\n+\n+class UnaryOp(_base_nodes.OperatorNode):\n     \"\"\"Class representing an :class:`ast.UnaryOp` node.\n \n     >>> import astroid\n@@ -3495,19 +4112,14 @@ def __init__(\n     def postinit(self, operand: NodeNG) -> None:\n         self.operand = operand\n \n-    # This is set by inference.py\n-    _infer_unaryop: ClassVar[\n-        InferBinaryOperation[UnaryOp, util.BadUnaryOperationMessage]\n-    ]\n-\n     def type_errors(self, context: InferenceContext | None = None):\n         \"\"\"Get a list of type errors which can occur during inference.\n \n-        Each TypeError is represented by a :class:`BadBinaryOperationMessage`,\n+        Each TypeError is represented by a :class:`BadUnaryOperationMessage`,\n         which holds the original exception.\n \n         :returns: The list of possible type errors.\n-        :rtype: list(BadBinaryOperationMessage)\n+        :rtype: list(BadUnaryOperationMessage)\n         \"\"\"\n         try:\n             results = self._infer_unaryop(context=context)\n@@ -3528,6 +4140,81 @@ def op_precedence(self):\n \n         return super().op_precedence()\n \n+    def _infer_unaryop(\n+        self: nodes.UnaryOp, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[\n+        InferenceResult | util.BadUnaryOperationMessage, None, InferenceErrorInfo\n+    ]:\n+        \"\"\"Infer what an UnaryOp should return when evaluated.\"\"\"\n+        from astroid.nodes import ClassDef  # pylint: disable=import-outside-toplevel\n+\n+        for operand in self.operand.infer(context):\n+            try:\n+                yield operand.infer_unary_op(self.op)\n+            except TypeError as exc:\n+                # The operand doesn't support this operation.\n+                yield util.BadUnaryOperationMessage(operand, self.op, exc)\n+            except AttributeError as exc:\n+                meth = UNARY_OP_METHOD[self.op]\n+                if meth is None:\n+                    # `not node`. Determine node's boolean\n+                    # value and negate its result, unless it is\n+                    # Uninferable, which will be returned as is.\n+                    bool_value = operand.bool_value()\n+                    if not isinstance(bool_value, util.UninferableBase):\n+                        yield const_factory(not bool_value)\n+                    else:\n+                        yield util.Uninferable\n+                else:\n+                    if not isinstance(operand, (Instance, ClassDef)):\n+                        # The operation was used on something which\n+                        # doesn't support it.\n+                        yield util.BadUnaryOperationMessage(operand, self.op, exc)\n+                        continue\n+\n+                    try:\n+                        try:\n+                            methods = dunder_lookup.lookup(operand, meth)\n+                        except AttributeInferenceError:\n+                            yield util.BadUnaryOperationMessage(operand, self.op, exc)\n+                            continue\n+\n+                        meth = methods[0]\n+                        inferred = next(meth.infer(context=context), None)\n+                        if (\n+                            isinstance(inferred, util.UninferableBase)\n+                            or not inferred.callable()\n+                        ):\n+                            continue\n+\n+                        context = copy_context(context)\n+                        context.boundnode = operand\n+                        context.callcontext = CallContext(args=[], callee=inferred)\n+\n+                        call_results = inferred.infer_call_result(self, context=context)\n+                        result = next(call_results, None)\n+                        if result is None:\n+                            # Failed to infer, return the same type.\n+                            yield operand\n+                        else:\n+                            yield result\n+                    except AttributeInferenceError as inner_exc:\n+                        # The unary operation special method was not found.\n+                        yield util.BadUnaryOperationMessage(operand, self.op, inner_exc)\n+                    except InferenceError:\n+                        yield util.Uninferable\n+\n+    @decorators.raise_if_nothing_inferred\n+    @decorators.path_wrapper\n+    def _infer(\n+        self: nodes.UnaryOp, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[InferenceResult, None, InferenceErrorInfo]:\n+        \"\"\"Infer what an UnaryOp should return when evaluated.\"\"\"\n+        yield from self._filter_operation_errors(\n+            self._infer_unaryop, context, util.BadUnaryOperationMessage\n+        )\n+        return InferenceErrorInfo(node=self, context=context)\n+\n \n class While(_base_nodes.MultiLineWithElseBlockNode, _base_nodes.Statement):\n     \"\"\"Class representing an :class:`ast.While` node.\n@@ -3671,7 +4358,7 @@ def postinit(\n             self.body = body\n         self.type_annotation = type_annotation\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[With]]\n+    assigned_stmts = protocols.with_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -3944,7 +4631,7 @@ def postinit(self, target: NodeNG, value: NodeNG) -> None:\n         self.target = target\n         self.value = value\n \n-    assigned_stmts: ClassVar[AssignedStmtsCall[NamedExpr]]\n+    assigned_stmts = protocols.named_expr_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -4345,17 +5032,7 @@ def postinit(\n         self.patterns = patterns\n         self.rest = rest\n \n-    assigned_stmts: ClassVar[\n-        Callable[\n-            [\n-                MatchMapping,\n-                AssignName,\n-                InferenceContext | None,\n-                None,\n-            ],\n-            Generator[NodeNG, None, None],\n-        ]\n-    ]\n+    assigned_stmts = protocols.match_mapping_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -4452,17 +5129,7 @@ def __init__(\n     def postinit(self, *, name: AssignName | None) -> None:\n         self.name = name\n \n-    assigned_stmts: ClassVar[\n-        Callable[\n-            [\n-                MatchStar,\n-                AssignName,\n-                InferenceContext | None,\n-                None,\n-            ],\n-            Generator[NodeNG, None, None],\n-        ]\n-    ]\n+    assigned_stmts = protocols.match_star_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\n@@ -4523,17 +5190,7 @@ def postinit(\n         self.pattern = pattern\n         self.name = name\n \n-    assigned_stmts: ClassVar[\n-        Callable[\n-            [\n-                MatchAs,\n-                AssignName,\n-                InferenceContext | None,\n-                None,\n-            ],\n-            Generator[NodeNG, None, None],\n-        ]\n-    ]\n+    assigned_stmts = protocols.match_as_assigned_stmts\n     \"\"\"Returns the assigned statement (non inferred) according to the assignment type.\n     See astroid/protocols.py for actual implementation.\n     \"\"\"\ndiff --git a/astroid/nodes/scoped_nodes/mixin.py b/astroid/nodes/scoped_nodes/mixin.py\nindex fa6aad412e..da03e06796 100644\n--- a/astroid/nodes/scoped_nodes/mixin.py\n+++ b/astroid/nodes/scoped_nodes/mixin.py\n@@ -9,7 +9,7 @@\n from typing import TYPE_CHECKING, TypeVar, overload\n \n from astroid.filter_statements import _filter_stmts\n-from astroid.nodes import node_classes, scoped_nodes\n+from astroid.nodes import _base_nodes, node_classes, scoped_nodes\n from astroid.nodes.scoped_nodes.utils import builtin_lookup\n from astroid.typing import InferenceResult, SuccessfulInferenceResult\n \n@@ -19,7 +19,7 @@\n _T = TypeVar(\"_T\")\n \n \n-class LocalsDictNodeNG(node_classes.LookupMixIn):\n+class LocalsDictNodeNG(_base_nodes.LookupMixIn):\n     \"\"\"this class provides locals handling common to Module, FunctionDef\n     and ClassDef nodes, including a dict like interface for direct access\n     to locals information\n@@ -52,7 +52,7 @@ def scope(self: _T) -> _T:\n         return self\n \n     def scope_lookup(\n-        self, node: node_classes.LookupMixIn, name: str, offset: int = 0\n+        self, node: _base_nodes.LookupMixIn, name: str, offset: int = 0\n     ) -> tuple[LocalsDictNodeNG, list[nodes.NodeNG]]:\n         \"\"\"Lookup where the given variable is assigned.\n \n@@ -70,7 +70,7 @@ def scope_lookup(\n         raise NotImplementedError\n \n     def _scope_lookup(\n-        self, node: node_classes.LookupMixIn, name: str, offset: int = 0\n+        self, node: _base_nodes.LookupMixIn, name: str, offset: int = 0\n     ) -> tuple[LocalsDictNodeNG, list[nodes.NodeNG]]:\n         \"\"\"XXX method for interfacing the scope lookup\"\"\"\n         try:\ndiff --git a/astroid/nodes/scoped_nodes/scoped_nodes.py b/astroid/nodes/scoped_nodes/scoped_nodes.py\nindex 94f4c53eeb..81a0c0e230 100644\n--- a/astroid/nodes/scoped_nodes/scoped_nodes.py\n+++ b/astroid/nodes/scoped_nodes/scoped_nodes.py\n@@ -16,9 +16,9 @@\n import warnings\n from collections.abc import Generator, Iterable, Iterator, Sequence\n from functools import cached_property, lru_cache\n-from typing import TYPE_CHECKING, ClassVar, Literal, NoReturn, TypeVar\n+from typing import TYPE_CHECKING, Any, ClassVar, Literal, NoReturn, TypeVar\n \n-from astroid import bases, util\n+from astroid import bases, protocols, util\n from astroid.const import IS_PYPY, PY38, PY39_PLUS, PYPY_7_3_11_PLUS\n from astroid.context import (\n     CallContext,\n@@ -44,10 +44,16 @@\n from astroid.nodes.scoped_nodes.mixin import ComprehensionScope, LocalsDictNodeNG\n from astroid.nodes.scoped_nodes.utils import builtin_lookup\n from astroid.nodes.utils import Position\n-from astroid.typing import InferBinaryOp, InferenceResult, SuccessfulInferenceResult\n+from astroid.typing import (\n+    InferBinaryOp,\n+    InferenceErrorInfo,\n+    InferenceResult,\n+    SuccessfulInferenceResult,\n+)\n \n if TYPE_CHECKING:\n-    from astroid import nodes\n+    from astroid import nodes, objects\n+    from astroid.nodes._base_nodes import LookupMixIn\n \n \n ITER_METHODS = (\"__iter__\", \"__getitem__\")\n@@ -285,7 +291,7 @@ def block_range(self, lineno: int) -> tuple[int, int]:\n         return self.fromlineno, self.tolineno\n \n     def scope_lookup(\n-        self, node: node_classes.LookupMixIn, name: str, offset: int = 0\n+        self, node: LookupMixIn, name: str, offset: int = 0\n     ) -> tuple[LocalsDictNodeNG, list[node_classes.NodeNG]]:\n         \"\"\"Lookup where the given variable is assigned.\n \n@@ -578,6 +584,11 @@ def frame(self: _T, *, future: Literal[None, True] = None) -> _T:\n         \"\"\"\n         return self\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[Module]:\n+        yield self\n+\n \n class GeneratorExp(ComprehensionScope):\n     \"\"\"Class representing an :class:`ast.GeneratorExp` node.\n@@ -961,7 +972,7 @@ def infer_call_result(\n         return self.body.infer(context)\n \n     def scope_lookup(\n-        self, node: node_classes.LookupMixIn, name: str, offset: int = 0\n+        self, node: LookupMixIn, name: str, offset: int = 0\n     ) -> tuple[LocalsDictNodeNG, list[NodeNG]]:\n         \"\"\"Lookup where the given names is assigned.\n \n@@ -1025,6 +1036,11 @@ def getattr(\n             return found_attrs\n         raise AttributeInferenceError(target=self, attribute=name)\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[Lambda]:\n+        yield self\n+\n \n class FunctionDef(\n     _base_nodes.MultiLineBlockNode,\n@@ -1469,6 +1485,44 @@ def is_generator(self) -> bool:\n         \"\"\"\n         return bool(next(self._get_yield_nodes_skip_lambdas(), False))\n \n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Generator[objects.Property | FunctionDef, None, InferenceErrorInfo]:\n+        from astroid import objects  # pylint: disable=import-outside-toplevel\n+\n+        if not self.decorators or not bases._is_property(self):\n+            yield self\n+            return InferenceErrorInfo(node=self, context=context)\n+\n+        # When inferring a property, we instantiate a new `objects.Property` object,\n+        # which in turn, because it inherits from `FunctionDef`, sets itself in the locals\n+        # of the wrapping frame. This means that every time we infer a property, the locals\n+        # are mutated with a new instance of the property. To avoid this, we detect this\n+        # scenario and avoid passing the `parent` argument to the constructor.\n+        parent_frame = self.parent.frame()\n+        property_already_in_parent_locals = self.name in parent_frame.locals and any(\n+            isinstance(val, objects.Property) for val in parent_frame.locals[self.name]\n+        )\n+        # We also don't want to pass parent if the definition is within a Try node\n+        if isinstance(\n+            self.parent,\n+            (node_classes.TryExcept, node_classes.TryFinally, node_classes.If),\n+        ):\n+            property_already_in_parent_locals = True\n+\n+        prop_func = objects.Property(\n+            function=self,\n+            name=self.name,\n+            lineno=self.lineno,\n+            parent=self.parent if not property_already_in_parent_locals else None,\n+            col_offset=self.col_offset,\n+        )\n+        if property_already_in_parent_locals:\n+            prop_func.parent = self.parent\n+        prop_func.postinit(body=[], args=self.args, doc_node=self.doc_node)\n+        yield prop_func\n+        return InferenceErrorInfo(node=self, context=context)\n+\n     def infer_yield_result(self, context: InferenceContext | None = None):\n         \"\"\"Infer what the function yields when called\n \n@@ -1600,7 +1654,7 @@ def get_children(self):\n         yield from self.body\n \n     def scope_lookup(\n-        self, node: node_classes.LookupMixIn, name: str, offset: int = 0\n+        self, node: LookupMixIn, name: str, offset: int = 0\n     ) -> tuple[LocalsDictNodeNG, list[nodes.NodeNG]]:\n         \"\"\"Lookup where the given name is assigned.\"\"\"\n         if name == \"__class__\":\n@@ -1848,7 +1902,9 @@ def __init__(\n         for local_name, node in self.implicit_locals():\n             self.add_local_node(node, local_name)\n \n-    infer_binary_op: ClassVar[InferBinaryOp[ClassDef]]\n+    infer_binary_op: ClassVar[\n+        InferBinaryOp[ClassDef]\n+    ] = protocols.instance_class_infer_binary_op\n \n     def implicit_parameters(self) -> Literal[1]:\n         return 1\n@@ -2080,7 +2136,7 @@ def infer_call_result(\n             yield self.instantiate_class()\n \n     def scope_lookup(\n-        self, node: node_classes.LookupMixIn, name: str, offset: int = 0\n+        self, node: LookupMixIn, name: str, offset: int = 0\n     ) -> tuple[LocalsDictNodeNG, list[nodes.NodeNG]]:\n         \"\"\"Lookup where the given name is assigned.\n \n@@ -2875,3 +2931,8 @@ def frame(self: _T, *, future: Literal[None, True] = None) -> _T:\n         :returns: The node itself.\n         \"\"\"\n         return self\n+\n+    def _infer(\n+        self, context: InferenceContext | None = None, **kwargs: Any\n+    ) -> Iterator[ClassDef]:\n+        yield self\ndiff --git a/astroid/protocols.py b/astroid/protocols.py\nindex e3b89b7ef7..f37c9c3256 100644\n--- a/astroid/protocols.py\n+++ b/astroid/protocols.py\n@@ -12,9 +12,9 @@\n import itertools\n import operator as operator_mod\n from collections.abc import Callable, Generator, Iterator, Sequence\n-from typing import Any, TypeVar\n+from typing import TYPE_CHECKING, Any, TypeVar\n \n-from astroid import arguments, bases, decorators, helpers, nodes, objects, util\n+from astroid import bases, decorators, nodes, util\n from astroid.const import Context\n from astroid.context import InferenceContext, copy_context\n from astroid.exceptions import (\n@@ -31,47 +31,11 @@\n     SuccessfulInferenceResult,\n )\n \n-_TupleListNodeT = TypeVar(\"_TupleListNodeT\", nodes.Tuple, nodes.List)\n-\n-\n-def _reflected_name(name) -> str:\n-    return \"__r\" + name[2:]\n-\n-\n-def _augmented_name(name) -> str:\n-    return \"__i\" + name[2:]\n-\n+if TYPE_CHECKING:\n+    _TupleListNodeT = TypeVar(\"_TupleListNodeT\", nodes.Tuple, nodes.List)\n \n _CONTEXTLIB_MGR = \"contextlib.contextmanager\"\n-BIN_OP_METHOD = {\n-    \"+\": \"__add__\",\n-    \"-\": \"__sub__\",\n-    \"/\": \"__truediv__\",\n-    \"//\": \"__floordiv__\",\n-    \"*\": \"__mul__\",\n-    \"**\": \"__pow__\",\n-    \"%\": \"__mod__\",\n-    \"&\": \"__and__\",\n-    \"|\": \"__or__\",\n-    \"^\": \"__xor__\",\n-    \"<<\": \"__lshift__\",\n-    \">>\": \"__rshift__\",\n-    \"@\": \"__matmul__\",\n-}\n-\n-REFLECTED_BIN_OP_METHOD = {\n-    key: _reflected_name(value) for (key, value) in BIN_OP_METHOD.items()\n-}\n-AUGMENTED_OP_METHOD = {\n-    key + \"=\": _augmented_name(value) for (key, value) in BIN_OP_METHOD.items()\n-}\n \n-UNARY_OP_METHOD = {\n-    \"+\": \"__pos__\",\n-    \"-\": \"__neg__\",\n-    \"~\": \"__invert__\",\n-    \"not\": None,  # XXX not '__nonzero__'\n-}\n _UNARY_OPERATORS: dict[str, Callable[[Any], Any]] = {\n     \"+\": operator_mod.pos,\n     \"-\": operator_mod.neg,\n@@ -93,11 +57,25 @@ def _infer_unary_op(obj: Any, op: str) -> ConstFactoryResult:\n     return nodes.const_factory(value)\n \n \n-nodes.Tuple.infer_unary_op = lambda self, op: _infer_unary_op(tuple(self.elts), op)\n-nodes.List.infer_unary_op = lambda self, op: _infer_unary_op(self.elts, op)\n-nodes.Set.infer_unary_op = lambda self, op: _infer_unary_op(set(self.elts), op)\n-nodes.Const.infer_unary_op = lambda self, op: _infer_unary_op(self.value, op)\n-nodes.Dict.infer_unary_op = lambda self, op: _infer_unary_op(dict(self.items), op)\n+def tuple_infer_unary_op(self, op):\n+    return _infer_unary_op(tuple(self.elts), op)\n+\n+\n+def list_infer_unary_op(self, op):\n+    return _infer_unary_op(self.elts, op)\n+\n+\n+def set_infer_unary_op(self, op):\n+    return _infer_unary_op(set(self.elts), op)\n+\n+\n+def const_infer_unary_op(self, op):\n+    return _infer_unary_op(self.value, op)\n+\n+\n+def dict_infer_unary_op(self, op):\n+    return _infer_unary_op(dict(self.items), op)\n+\n \n # Binary operations\n \n@@ -157,15 +135,14 @@ def const_infer_binary_op(\n         yield not_implemented\n \n \n-nodes.Const.infer_binary_op = const_infer_binary_op\n-\n-\n def _multiply_seq_by_int(\n     self: _TupleListNodeT,\n     opnode: nodes.AugAssign | nodes.BinOp,\n     other: nodes.Const,\n     context: InferenceContext,\n ) -> _TupleListNodeT:\n+    from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n     node = self.__class__(parent=opnode)\n     filtered_elts = (\n         helpers.safe_infer(elt, context) or util.Uninferable\n@@ -205,6 +182,8 @@ def tl_infer_binary_op(\n     or list. This refers to the left-hand side of the operation, so:\n     'tuple() + 1' or '[] + A()'\n     \"\"\"\n+    from astroid import helpers  # pylint: disable=import-outside-toplevel\n+\n     # For tuples and list the boundnode is no longer the tuple or list instance\n     context.boundnode = None\n     not_implemented = nodes.Const(NotImplemented)\n@@ -233,13 +212,9 @@ def tl_infer_binary_op(\n         yield not_implemented\n \n \n-nodes.Tuple.infer_binary_op = tl_infer_binary_op\n-nodes.List.infer_binary_op = tl_infer_binary_op\n-\n-\n @decorators.yes_if_nothing_inferred\n def instance_class_infer_binary_op(\n-    self: bases.Instance | nodes.ClassDef,\n+    self: nodes.ClassDef,\n     opnode: nodes.AugAssign | nodes.BinOp,\n     operator: str,\n     other: InferenceResult,\n@@ -249,12 +224,8 @@ def instance_class_infer_binary_op(\n     return method.infer_call_result(self, context)\n \n \n-bases.Instance.infer_binary_op = instance_class_infer_binary_op\n-nodes.ClassDef.infer_binary_op = instance_class_infer_binary_op\n-\n-\n # assignment ##################################################################\n-\n+# pylint: disable-next=pointless-string-statement\n \"\"\"The assigned_stmts method is responsible to return the assigned statement\n (e.g. not inferred) according to the assignment type.\n \n@@ -337,10 +308,6 @@ def for_assigned_stmts(\n     }\n \n \n-nodes.For.assigned_stmts = for_assigned_stmts\n-nodes.Comprehension.assigned_stmts = for_assigned_stmts\n-\n-\n def sequence_assigned_stmts(\n     self: nodes.Tuple | nodes.List,\n     node: node_classes.AssignedStmtsPossibleNode = None,\n@@ -365,10 +332,6 @@ def sequence_assigned_stmts(\n     )\n \n \n-nodes.Tuple.assigned_stmts = sequence_assigned_stmts\n-nodes.List.assigned_stmts = sequence_assigned_stmts\n-\n-\n def assend_assigned_stmts(\n     self: nodes.AssignName | nodes.AssignAttr,\n     node: node_classes.AssignedStmtsPossibleNode = None,\n@@ -378,15 +341,13 @@ def assend_assigned_stmts(\n     return self.parent.assigned_stmts(node=self, context=context)\n \n \n-nodes.AssignName.assigned_stmts = assend_assigned_stmts\n-nodes.AssignAttr.assigned_stmts = assend_assigned_stmts\n-\n-\n def _arguments_infer_argname(\n     self, name: str | None, context: InferenceContext\n ) -> Generator[InferenceResult, None, None]:\n     # arguments information may be missing, in which case we can't do anything\n     # more\n+    from astroid import arguments  # pylint: disable=import-outside-toplevel\n+\n     if not (self.arguments or self.vararg or self.kwarg):\n         yield util.Uninferable\n         return\n@@ -449,6 +410,8 @@ def arguments_assigned_stmts(\n     context: InferenceContext | None = None,\n     assign_path: list[int] | None = None,\n ) -> Any:\n+    from astroid import arguments  # pylint: disable=import-outside-toplevel\n+\n     try:\n         node_name = node.name  # type: ignore[union-attr]\n     except AttributeError:\n@@ -472,9 +435,6 @@ def arguments_assigned_stmts(\n     return _arguments_infer_argname(self, node_name, context)\n \n \n-nodes.Arguments.assigned_stmts = arguments_assigned_stmts\n-\n-\n @decorators.raise_if_nothing_inferred\n def assign_assigned_stmts(\n     self: nodes.AugAssign | nodes.Assign | nodes.AnnAssign,\n@@ -510,11 +470,6 @@ def assign_annassigned_stmts(\n             yield inferred\n \n \n-nodes.Assign.assigned_stmts = assign_assigned_stmts\n-nodes.AnnAssign.assigned_stmts = assign_annassigned_stmts\n-nodes.AugAssign.assigned_stmts = assign_assigned_stmts\n-\n-\n def _resolve_assignment_parts(parts, assign_path, context):\n     \"\"\"Recursive function to resolve multiple assignments.\"\"\"\n     assign_path = assign_path[:]\n@@ -562,6 +517,8 @@ def excepthandler_assigned_stmts(\n     context: InferenceContext | None = None,\n     assign_path: list[int] | None = None,\n ) -> Any:\n+    from astroid import objects  # pylint: disable=import-outside-toplevel\n+\n     for assigned in node_classes.unpack_infer(self.type):\n         if isinstance(assigned, nodes.ClassDef):\n             assigned = objects.ExceptionInstance(assigned)\n@@ -575,9 +532,6 @@ def excepthandler_assigned_stmts(\n     }\n \n \n-nodes.ExceptHandler.assigned_stmts = excepthandler_assigned_stmts\n-\n-\n def _infer_context_manager(self, mgr, context):\n     try:\n         inferred = next(mgr.infer(context=context))\n@@ -696,9 +650,6 @@ def __enter__(self):\n     }\n \n \n-nodes.With.assigned_stmts = with_assigned_stmts\n-\n-\n @decorators.raise_if_nothing_inferred\n def named_expr_assigned_stmts(\n     self: nodes.NamedExpr,\n@@ -718,9 +669,6 @@ def named_expr_assigned_stmts(\n         )\n \n \n-nodes.NamedExpr.assigned_stmts = named_expr_assigned_stmts\n-\n-\n @decorators.yes_if_nothing_inferred\n def starred_assigned_stmts(  # noqa: C901\n     self: nodes.Starred,\n@@ -918,9 +866,6 @@ def _determine_starred_iteration_lookups(\n         yield util.Uninferable\n \n \n-nodes.Starred.assigned_stmts = starred_assigned_stmts\n-\n-\n @decorators.yes_if_nothing_inferred\n def match_mapping_assigned_stmts(\n     self: nodes.MatchMapping,\n@@ -935,9 +880,6 @@ def match_mapping_assigned_stmts(\n     yield\n \n \n-nodes.MatchMapping.assigned_stmts = match_mapping_assigned_stmts\n-\n-\n @decorators.yes_if_nothing_inferred\n def match_star_assigned_stmts(\n     self: nodes.MatchStar,\n@@ -952,9 +894,6 @@ def match_star_assigned_stmts(\n     yield\n \n \n-nodes.MatchStar.assigned_stmts = match_star_assigned_stmts\n-\n-\n @decorators.yes_if_nothing_inferred\n def match_as_assigned_stmts(\n     self: nodes.MatchAs,\n@@ -971,6 +910,3 @@ def match_as_assigned_stmts(\n         and self.pattern is None\n     ):\n         yield self.parent.parent.subject\n-\n-\n-nodes.MatchAs.assigned_stmts = match_as_assigned_stmts\ndiff --git a/doc/api/base_nodes.rst b/doc/api/base_nodes.rst\nindex 6253ce5ce5..14f7ab1071 100644\n--- a/doc/api/base_nodes.rst\n+++ b/doc/api/base_nodes.rst\n@@ -12,7 +12,7 @@ These are abstract node classes that :ref:`other nodes <nodes>` inherit from.\n    astroid.nodes._base_nodes.FilterStmtsBaseNode\n    astroid.nodes._base_nodes.ImportNode\n      astroid.nodes.LocalsDictNodeNG\n-   astroid.nodes.node_classes.LookupMixIn\n+   astroid.nodes._base_nodes.LookupMixIn\n    astroid.nodes.NodeNG\n    astroid.nodes._base_nodes.ParentAssignNode\n    astroid.nodes.Statement\n@@ -33,7 +33,7 @@ These are abstract node classes that :ref:`other nodes <nodes>` inherit from.\n \n .. autoclass:: astroid.nodes.LocalsDictNodeNG\n \n-.. autoclass:: astroid.nodes.node_classes.LookupMixIn\n+.. autoclass:: astroid.nodes._base_nodes.LookupMixIn\n \n .. autoclass:: astroid.nodes.NodeNG\n \n",
  "problem_statement": "Remove monkey-patching of methods onto classes\nIn [this comment](https://github.com/PyCQA/astroid/issues/170#issuecomment-163118573), @PCManticore stated that there was a plan to remove monkey-patching of methods onto classes. inference.py and protocols.py seem to suggest that this hasn't happened.\r\n\r\nIs this still a design goal?\r\n\r\nIt looks to me like this would be a fairly mechanical change. I am assuming that since it hasn't happened yet, I am missing something. Is it simply a \"haven't had time\" issue?\n",
  "pull_number": 2171,
  "repo": "pylint-dev/astroid",
  "test_patch": "diff --git a/tests/test_inference.py b/tests/test_inference.py\nindex 96778b89d3..03d0e2c744 100644\n--- a/tests/test_inference.py\n+++ b/tests/test_inference.py\n@@ -41,7 +41,6 @@\n     InferenceError,\n     NotFoundError,\n )\n-from astroid.inference import infer_end as inference_infer_end\n from astroid.objects import ExceptionInstance\n \n from . import resources\n@@ -71,7 +70,7 @@ def infer_default(self: Any, *args: InferenceContext) -> None:\n             raise InferenceError\n \n         infer_default = decoratorsmod.path_wrapper(infer_default)\n-        infer_end = decoratorsmod.path_wrapper(inference_infer_end)\n+        infer_end = decoratorsmod.path_wrapper(Slice._infer)\n         with self.assertRaises(InferenceError):\n             next(infer_default(1))\n         self.assertEqual(next(infer_end(1)), 1)\ndiff --git a/tests/test_manager.py b/tests/test_manager.py\nindex 56b09945ba..6455a6e5d3 100644\n--- a/tests/test_manager.py\n+++ b/tests/test_manager.py\n@@ -409,7 +409,7 @@ def test_borg(self) -> None:\n class ClearCacheTest(unittest.TestCase):\n     def test_clear_cache_clears_other_lru_caches(self) -> None:\n         lrus = (\n-            astroid.nodes.node_classes.LookupMixIn.lookup,\n+            astroid.nodes._base_nodes.LookupMixIn.lookup,\n             astroid.modutils._cache_normalize_path_,\n             util.is_namespace,\n             astroid.interpreter.objectmodel.ObjectModel.attributes,\ndiff --git a/tests/test_nodes.py b/tests/test_nodes.py\nindex 7a4990cddb..41429fc5ab 100644\n--- a/tests/test_nodes.py\n+++ b/tests/test_nodes.py\n@@ -1916,8 +1916,7 @@ def return_from_match(x):\n     [\n         node\n         for node in astroid.nodes.ALL_NODE_CLASSES\n-        if node.__name__\n-        not in [\"_BaseContainer\", \"BaseContainer\", \"NodeNG\", \"const_factory\"]\n+        if node.__name__ not in [\"BaseContainer\", \"NodeNG\", \"const_factory\"]\n     ],\n )\n @pytest.mark.filterwarnings(\"error\")\n",
  "commit_url": "https://github.com/pylint-dev/astroid/tree/8d57ce2f3e226c2ac3cdd7f6a57dac2dd5ec5a4b"
}