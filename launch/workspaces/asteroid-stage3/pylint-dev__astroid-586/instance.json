{
  "all_hints_text": "The inference result of `args` at the end of the above code:\r\n\r\n- has `16384` items\r\n- includes multiple duplicates with lines closer to the bottom being referenced more\r\n\r\n`log2(16384)` is `14` which is equivalent to the number of `AugAssign`s in the above code, so it is definitely a n^2 perf issue\r\n\r\n---\r\n\r\nIt looks like inference is (correctly?) inferencing all possible permutations of the list:\r\n\r\n```\r\ncode = \"\"\"\r\nargs = []\r\n\r\nif True:\r\n    args += ['a']\r\n\r\nif True:\r\n    args += ['b']\r\n\r\nif True:\r\n    args += ['c']\r\n    \r\nargs #@\r\n\"\"\"\r\n\r\nresult  = astroid.extract_node(code).inferred()\r\n[result.as_string() for result in result]\r\n```\r\n\r\n```\r\n['[]',\r\n \"['a']\",\r\n \"['b']\",\r\n \"['a', 'b']\",\r\n \"['c']\",\r\n \"['a', 'c']\",\r\n \"['b', 'c']\",\r\n \"['a', 'b', 'c']\"]\r\n```\r\n\r\nNot too sure what to do about this\nIs this an actual example of something that can happen in the wild or is just an artificial example? I wonder if we'd need to introduce some sort of recursion guard in the inference, that will stop after a certain amount of recursive inferred branches. This should prevent a couple of performance issues where we'd try to infer all the potential values that a complex function could generate, although I'm not yet exactly sure on how the mechanics would work for that guard.\nYes, this is an actual example which happened a few days ago. It appeared in a function which takes takes a setting dictionary and constructs the command line arguments for a monitoring plugin. Basically one commit increased the pylint running time of our project from about 0:30 h to 5:30 h.\nOuch, that's quite the jump! Curious how big your project in terms of LOC is if it already takes half an hour without this bug.\nAccording to cloc roughly 2000 Python files with 250000 lines of code. Without this issue and a bit of tuning it's now down to 0:10 h again.\nJust for clarification: Spell checking in pylint seems to take ages, so we took out the checks ``wrong-spelling-in-comment`` and ``wrong-spelling-in-docstring``. This brought down the pylint runtime from roughly 30-40 min to 11 min. Just in case anybody wonders...\r\n\nI think we could open an issue on pylint for that performance problem\r\n\r\n@PCManticore \r\nWe could limit the number of possible inferences in `cache_generator` by counting the number of yielded inferences, and, if it hit some limit (like 1000), just append `Uninferable` at the end and return from the generator. It could even be a environment variable set lower for performance on bigger projects.\n@brycepg Good catch, that might work! \n\n",
  "base_commit": "0b7638a0d2a1d29b3bba690e779dd02d89dbac81",
  "commit_urls": [
    "https://github.com/pylint-dev/astroid/commit/5d2b14cd6fe72fa52f937047a51bba17f099da80"
  ],
  "created_at": "2018-07-06T04:18:35Z",
  "hints_text": "The inference result of `args` at the end of the above code:\r\n\r\n- has `16384` items\r\n- includes multiple duplicates with lines closer to the bottom being referenced more\r\n\r\n`log2(16384)` is `14` which is equivalent to the number of `AugAssign`s in the above code, so it is definitely a n^2 perf issue\r\n\r\n---\r\n\r\nIt looks like inference is (correctly?) inferencing all possible permutations of the list:\r\n\r\n```\r\ncode = \"\"\"\r\nargs = []\r\n\r\nif True:\r\n    args += ['a']\r\n\r\nif True:\r\n    args += ['b']\r\n\r\nif True:\r\n    args += ['c']\r\n    \r\nargs #@\r\n\"\"\"\r\n\r\nresult  = astroid.extract_node(code).inferred()\r\n[result.as_string() for result in result]\r\n```\r\n\r\n```\r\n['[]',\r\n \"['a']\",\r\n \"['b']\",\r\n \"['a', 'b']\",\r\n \"['c']\",\r\n \"['a', 'c']\",\r\n \"['b', 'c']\",\r\n \"['a', 'b', 'c']\"]\r\n```\r\n\r\nNot too sure what to do about this\nIs this an actual example of something that can happen in the wild or is just an artificial example? I wonder if we'd need to introduce some sort of recursion guard in the inference, that will stop after a certain amount of recursive inferred branches. This should prevent a couple of performance issues where we'd try to infer all the potential values that a complex function could generate, although I'm not yet exactly sure on how the mechanics would work for that guard.\nYes, this is an actual example which happened a few days ago. It appeared in a function which takes takes a setting dictionary and constructs the command line arguments for a monitoring plugin. Basically one commit increased the pylint running time of our project from about 0:30 h to 5:30 h.\nOuch, that's quite the jump! Curious how big your project in terms of LOC is if it already takes half an hour without this bug.\nAccording to cloc roughly 2000 Python files with 250000 lines of code. Without this issue and a bit of tuning it's now down to 0:10 h again.\nJust for clarification: Spell checking in pylint seems to take ages, so we took out the checks ``wrong-spelling-in-comment`` and ``wrong-spelling-in-docstring``. This brought down the pylint runtime from roughly 30-40 min to 11 min. Just in case anybody wonders...\r\n\nI think we could open an issue on pylint for that performance problem\r\n\r\n@PCManticore \r\nWe could limit the number of possible inferences in `cache_generator` by counting the number of yielded inferences, and, if it hit some limit (like 1000), just append `Uninferable` at the end and return from the generator. It could even be a environment variable set lower for performance on bigger projects.\n@brycepg Good catch, that might work! \n\n",
  "instance_id": "pylint-dev__astroid-586",
  "issue_numbers": [
    579
  ],
  "language": "python",
  "patch": "diff --git a/ChangeLog b/ChangeLog\nindex cd4d76eeb1..211fbb75e5 100644\n--- a/ChangeLog\n+++ b/ChangeLog\n@@ -157,6 +157,12 @@ Release Date: Unknown\n \n      Close PyCQA/pylint#2159\n \n+   * Limit the maximum amount of interable result in an NodeNG.infer() call to\n+    100 by default for performance issues with variables with large amounts of\n+    possible values.\n+    The max inferable value can be tuned by setting the ASTROID_MAX_INFERABLE environment\n+    variable at start up.\n+\n \n What's New in astroid 1.6.0?\n ============================\ndiff --git a/astroid/manager.py b/astroid/manager.py\nindex c1caf15146..c755366172 100644\n--- a/astroid/manager.py\n+++ b/astroid/manager.py\n@@ -52,6 +52,8 @@ def __init__(self):\n             # Export these APIs for convenience\n             self.register_transform = self._transform.register_transform\n             self.unregister_transform = self._transform.unregister_transform\n+            self.max_inferable = int(\n+                os.environ.get(\"ASTROID_MAX_INFERABLE\", 100))\n \n     def visit_transforms(self, node):\n         \"\"\"Visit the transforms and apply them to the given *node*.\"\"\"\ndiff --git a/astroid/node_classes.py b/astroid/node_classes.py\nindex a17af1a22e..a3c02fcf66 100644\n--- a/astroid/node_classes.py\n+++ b/astroid/node_classes.py\n@@ -323,7 +323,9 @@ def infer(self, context=None, **kwargs):\n         if key in context.inferred:\n             return iter(context.inferred[key])\n \n-        return context.cache_generator(key, self._infer(context, **kwargs))\n+        gen = context.cache_generator(\n+            key, self._infer(context, **kwargs))\n+        return util.limit_inference(gen, MANAGER.max_inferable)\n \n     def _repr_name(self):\n         \"\"\"Get a name for nice representation.\ndiff --git a/astroid/util.py b/astroid/util.py\nindex a53109707a..8497b34a91 100644\n--- a/astroid/util.py\n+++ b/astroid/util.py\n@@ -5,6 +5,7 @@\n # For details: https://github.com/PyCQA/astroid/blob/master/COPYING.LESSER\n \n import warnings\n+from itertools import islice\n \n import importlib\n import lazy_object_proxy\n@@ -126,5 +127,28 @@ def proxy_alias(alias_name, node_type):\n     return proxy(lambda: node_type)\n \n \n+def limit_inference(iterator, size):\n+    \"\"\"Limit inference amount.\n+\n+    Limit inference amount to help with performance issues with\n+    exponentially exploding possible results.\n+\n+    :param iterator: Inference generator to limit\n+    :type iterator: Iterator(NodeNG)\n+\n+    :param size: Maximum mount of nodes yielded plus an\n+        Uninferable at the end if limit reached\n+    :type size: int\n+\n+    :yields: A possibly modified generator\n+    :rtype param: Iterable\n+    \"\"\"\n+    yield from islice(iterator, size)\n+    has_more = next(iterator, False)\n+    if has_more is not False:\n+        yield Uninferable\n+        return\n+\n+\n # Backwards-compatibility aliases\n YES = Uninferable\n",
  "problem_statement": "Type inference performance issue\nIn pylint 1.9.2 astroids type inference performs very badly for the code below:\r\n\r\n```\r\nargs = []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args += []\r\n\r\nif True:\r\n    args.append('')\r\n```\r\n\r\nIf the `args.append('')` appears in the first if statement pylint finishes almost immediately. If you move it to the end it already takes more than 7s. Profiling shows that the running time and number of calls to the function `_infer_binary_operation` increases exponentially \r\n\r\nThe issue can be reproduced in a virtual environment with only pylint installed and an empty pylintrc.\n",
  "pull_number": 586,
  "repo": "pylint-dev/astroid",
  "test_patch": "diff --git a/astroid/tests/unittest_inference.py b/astroid/tests/unittest_inference.py\nindex 5ee53d1f0c..5f9194c387 100644\n--- a/astroid/tests/unittest_inference.py\n+++ b/astroid/tests/unittest_inference.py\n@@ -15,6 +15,7 @@\n import sys\n from functools import partial\n import unittest\n+from unittest.mock import patch\n \n import pytest\n \n@@ -4656,5 +4657,34 @@ def f(**kwargs):\n         assert next(extract_node(code).infer()).as_string() == \"{'f': 1}\"\n \n \n+def test_limit_inference_result_amount():\n+    \"\"\"Test setting limit inference result amount\"\"\"\n+    code = \"\"\"\n+    args = []\n+\n+    if True:\n+        args += ['a']\n+\n+    if True:\n+        args += ['b']\n+\n+    if True:\n+        args += ['c']\n+\n+    if True:\n+        args += ['d']\n+\n+    args #@\n+    \"\"\"\n+    result = extract_node(code).inferred()\n+    assert len(result) == 16\n+    with patch('astroid.node_classes.MANAGER.max_inferable', 4):\n+        result_limited = extract_node(code).inferred()\n+    # Can't guarentee exact size\n+    assert len(result_limited) < 16\n+    # Will not always be at the end\n+    assert util.Uninferable in result_limited\n+\n+\n if __name__ == '__main__':\n     unittest.main()\n",
  "commit_url": "https://github.com/pylint-dev/astroid/tree/0b7638a0d2a1d29b3bba690e779dd02d89dbac81"
}